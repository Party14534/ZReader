<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Applied Cryptography, Second Edition: Protocols, Algorithms, and Source Code in C</title>
    <meta content="Bruce Schneier" name="author"/>
    <meta content="An introduction to cryptography." name="description"/>
    <meta content="programming,cryptography" name="keywords"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<div id="book" class="calibre1">
<h1 class="chapter" id="11">Chapter 11 <br class="calibre3"/>
Mathematical Background</h1>

<h3 id="11.1" class="calibre7">11.1 Information Theory</h3>

<p class="calibre9">Modern information theory was first published in 1948 by Claude Elmwood
Shannon [<a href="Applied%20Cryptography_split_036.html#r1431" class="calibre5 pcalibre">1431</a>,<a href="Applied%20Cryptography_split_036.html#r1432" class="calibre5 pcalibre">1432</a>]. (His papers have been reprinted by the IEEE Press
[<a href="Applied%20Cryptography_split_036.html#r1433" class="calibre5 pcalibre">1433</a>].) For a good mathematical treatment of the topic, consult [<a href="Applied%20Cryptography_split_035.html#r593" class="calibre5 pcalibre">593</a>]. In this
section, I will just sketch some important ideas.</p>

<h4 class="calibre8">Entropy and Uncertainty</h4>

<p class="calibre9">Information theory defines the <b class="calibre10">amount of information</b> in a message as the
minimum number of bits needed to encode all possible meanings of that
message, assuming all messages are equally likely. For example, the
day-of-the-week field in a database contains no more than 3 bits of
information, because the information can be encoded with 3 bits:</p>

<pre class="calibre20">000 = Sunday
001 = Monday
010 = Tuesday
011 = Wednesday
100 = Thursday
101 = Friday
110 = Saturday
111 is unused
</pre>

<p class="calibre9">If this information were represented by corresponding ASCII character strings,
it would take up more memory space but would not contain any more
information. Similarly, the “sex” field of a database contains only 1 bit of
information, even though it might be stored as one of two 6-byte ASCII
strings: “MALE” or “FEMALE.”</p>

<p class="calibre9">Formally, the amount of information in a message <i class="calibre12">M</i> is measured by the
<b class="calibre10">entropy</b> of a message, denoted by <i class="calibre12">H</i>(<i class="calibre12">M</i>). The entropy of a message indicating sex is 1 bit; the entropy of a message indicating the day of the week is slightly
less than 3 bits. In general, the entropy of a message measured in bits is log<sub class="calibre15">2</sub><i class="calibre12">n</i>,
in which <i class="calibre12">n</i> is the number of possible meanings. This assumes that each
meaning is equally likely.</p>

<p class="calibre9">The entropy of a message also measures its <b class="calibre10">uncertainty</b>. This is the number of
plaintext bits needed to be recovered when the message is scrambled in
ciphertext in order to learn the plaintext. For example, if the ciphertext block
“<code class="calibre18">QHP*5M</code>” is either “MALE” or “FEMALE, ” then the uncertainty of the
message is 1. A cryptanalyst has to learn only one well-chosen bit to recover
the message.</p>

<h4 class="calibre8">Rate of a Language</h4>

<p class="calibre9">For a given language, the <b class="calibre10">rate of the language</b> is</p>

<p class="math"><i class="calibre12">r</i> = <i class="calibre12">H</i>(<i class="calibre12">M</i>)/<i class="calibre12">N</i>
</p>

<p class="calibre9">in which <i class="calibre12">N</i> is the length of the message. The rate of normal English takes
various values between 1.0 bits/letter and 1.5 bits/letter, for large values of <i class="calibre12">N</i>.
Shannon, in [<a href="Applied%20Cryptography_split_036.html#r1434" class="calibre5 pcalibre">1434</a>], said that the entropy depends on the length of the text.
Specifically he indicated a rate of 2.3 bits/letter for 8-letter chunks, but the rate
drops to between 1.3 and 1.5 for 16-letter chunks. Thomas Cover used a
gambling estimating technique and found an entropy of 1.3 bits/character
[<a href="Applied%20Cryptography_split_035.html#r386" class="calibre5 pcalibre">386</a>]. (I’ll use 1.3 in this book.) The <b class="calibre10">absolute rate</b> of a language is the
maximum number of bits that can be coded in each character, assuming each
character sequence is equally likely. If there are <i class="calibre12">L</i> characters in a language, the absolute rate is:</p>

<p class="math"><i class="calibre12">R</i> = log<sub class="calibre15">2</sub><i class="calibre12">L</i>
</p>

<p class="calibre9">This is the maximum entropy of the individual characters.</p>

<p class="calibre9">For English, with 26 letters, the absolute rate is log<sub class="calibre15">2</sub>26, or about 4.7 bits/letter.
It should come as no surprise to anyone that the actual rate of English is much
less than the absolute rate; natural language is highly redundant.</p>

<p class="calibre9">The <b class="calibre10">redundancy</b> of a language, denoted <i class="calibre12">D</i>, is defined by:</p>

<p class="math"><i class="calibre12">D</i> = <i class="calibre12">R - r</i>
</p>

<p class="calibre9">Given that the rate of English is 1.3, the redundancy is 3.4 bits/letter. This
means that each English character carries 3.4 bits of redundant information.</p>

<p class="calibre9">An ASCII message that is nothing more than printed English has 1.3 bits of
information per byte of message. This means it has 6.7 bits of redundant
information, giving it an overall redundancy of 0.84 bits of information per bit
of ASCII text, and an entropy of 0.16 bits of information per bit of ASCII text.
The same message in BAUDOT, at 5 bits per character, has a redundancy of
0.74 bits per bit and an entropy of 0.26 bits per bit. Spacing, punctuation,
numbers, and formatting modify these results.</p>

<h4 class="calibre8">Security of a Cryptosystem</h4>

<p class="calibre9">Shannon defined a precise mathematical model of what it means for a
cryptosystem to be secure. The goal of a cryptanalyst is to determine the key
<i class="calibre12">K</i>, the plaintext <i class="calibre12">P</i>, or both. However, he may be satisfied with some
probabilistic information about <i class="calibre12">P:</i> whether it is digitized audio, German text, spreadsheet data, or something else.</p>

<p class="calibre9">In most real-world cryptanalysis, the cryptanalyst has some probabilistic
information about <i class="calibre12">P</i> before he even starts. He probably knows the language of
the plaintext. This language has a certain redundancy associated with it. If it is
a message to Bob, it probably begins with “Dear Bob.” Certainly “Dear Bob”
is more probable than “e8T&amp;g [, m.” The purpose of cryptanalysis is to
modify the probabilities associated with each possible plaintext. Eventually
one plaintext will emerge from the pile of possible plaintexts as certain (or at
least, very probable).</p>

<p class="calibre9">There is such a thing as a cryptosystem that achieves <b class="calibre10">perfect secrecy</b>: a
cryptosystem in which the ciphertext yields no possible information about the
plaintext (except possibly its length). Shannon theorized that it is only possible
if the number of possible keys is at least as large as the number of possible
messages. In other words, the key must be at least as long as the message
itself, and no key can be reused. In still other words, the one-time pad (see
<a href="Applied%20Cryptography_split_001.html#1.5" class="calibre5 pcalibre">Section 1.5</a>) is the only cryptosystem that achieves perfect secrecy.</p>

<p class="calibre9">Perfect secrecy aside, the ciphertext unavoidably yields some information
about the corresponding plaintext. A good cryptographic algorithm keeps this
information to a minimum; a good cryptanalyst exploits this information to
determine the plaintext.</p>

<p class="calibre9">Cryptanalysts use the natural redundancy of language to reduce the number of
possible plaintexts. The more redundant the language, the easier it is to
cryptanalyze. This is the reason that many real-world cryptographic
implementations use a compression program to reduce the size of the text
before encrypting it. Compression reduces the redundancy of a message as
well as the work required to encrypt and decrypt.</p>

<p class="calibre9">The entropy of a cryptosystem is a measure of the size of the keyspace, <i class="calibre12">K</i>. It is approximated by the base two logarithm of the number of keys:</p>

<p class="math"><i class="calibre12">H</i>(<i class="calibre12">K</i>) = log<sub class="calibre15">2</sub><i class="calibre12">K</i>
</p>

<p class="calibre9">A cryptosystem with a 64-bit key has an entropy of 64 bits; a cryptosystem
with a 56-bit key has an entropy of 56 bits. In general, the greater the entropy,
the harder it is to break a cryptosystem.</p>

<h4 class="calibre8">Unicity Distance</h4>

<p class="calibre9">For a message of length <i class="calibre12">n</i>, the number of different keys that will decipher a
ciphertext message to some intelligible plaintext in the same language as the
original plaintext (such as an English text string) is given by the following
formula [<a href="Applied%20Cryptography_split_035.html#r712" class="calibre5 pcalibre">712</a>,<a href="Applied%20Cryptography_split_035.html#r95" class="calibre5 pcalibre">95</a>]:</p>

<p class="math">2<sup class="calibre19"><i class="calibre22">H</i>(<i class="calibre22">K</i>)-<i class="calibre22">nD</i></sup> - 1
</p>

<p class="calibre9">Shannon [<a href="Applied%20Cryptography_split_036.html#r1432" class="calibre5 pcalibre">1432</a>] defined the <b class="calibre10">unicity distance</b>, <i class="calibre12">U</i>, also called the unicity point, as an approximation of the amount of ciphertext such that the sum of the real
information (entropy) in the corresponding plaintext plus the entropy of the
encryption key equals the number of ciphertext bits used. He then went on to
show that ciphertexts longer than this distance are reasonably certain to have
only one meaningful decryption. Ciphertexts significantly shorter than this are
likely to have multiple, equally valid decryptions and therefore gain security
from the opponent’s difficulty in choosing the correct one.</p>

<p class="calibre9">For most symmetric cryptosystems, the unicity distance is defined as the
entropy of the cryptosystem divided by the redundancy of the language.</p>

<p class="math"><i class="calibre12">U</i> = <i class="calibre12">H</i>(<i class="calibre12">K</i>)/<i class="calibre12">D</i>
</p>

<p class="calibre9">Unicity distance does not make deterministic predictions, but gives
probabilistic results. Unicity distance estimates the minimum amount of
ciphertext for which it is likely that there is only a single intelligible plaintext
decryption when a brute-force attack is attempted. Generally, the longer the
unicity distance, the better the cryptosystem. For DES, with a 56-bit key, and
an ASCII English message, the unicity distance is about 8.2 ASCII characters
or 66 bits. Table 11.1 gives the unicity distances for varying key lengths. The
unicity distances for some classical cryptosystems are found in [<a href="Applied%20Cryptography_split_035.html#r445" class="calibre5 pcalibre">445</a>].</p>

<table class="data-table3" id="table-11-1">
<caption class="calibre23">Table 11.1 - Unicity Distances of ASCII Text Encrypted with Algorithms with Varying Key Lengths</caption>
<tbody class="calibre24"><tr class="calibre25">
<th class="calibre26">Key Length (in bits)</th>
<th class="calibre26">Unicity Distance (in characters)</th>
</tr>
<tr class="calibre25"><td class="calibre27">40</td><td class="calibre27">5.9</td></tr>
<tr class="calibre25"><td class="calibre27">56</td><td class="calibre27">8.2</td></tr>
<tr class="calibre25"><td class="calibre27">64</td><td class="calibre27">9.4</td></tr>
<tr class="calibre25"><td class="calibre27">80</td><td class="calibre27">11.8</td></tr>
<tr class="calibre25"><td class="calibre27">128</td><td class="calibre27">18.8</td></tr>
<tr class="calibre25"><td class="calibre28">256</td><td class="calibre28">37.6</td></tr>
</tbody></table>

<p class="calibre39">Unicity distance is not a measure of how much ciphertext is required for
cryptanalysis, but how much ciphertext is required for there to be only one
reasonable solution for cryptanalysis. A cryptosystem may be computationally
infeasible to break even if it is theoretically possible to break it with a small
amount of ciphertext. (The largely esoteric theory of relativized cryptography
is relevant here [<a href="Applied%20Cryptography_split_035.html#r230" class="calibre5 pcalibre">230</a>,<a href="Applied%20Cryptography_split_035.html#r231" class="calibre5 pcalibre">231</a>,<a href="Applied%20Cryptography_split_035.html#r232" class="calibre5 pcalibre">232</a>,<a href="Applied%20Cryptography_split_035.html#r233" class="calibre5 pcalibre">233</a>,<a href="Applied%20Cryptography_split_035.html#r234" class="calibre5 pcalibre">234</a>,<a href="Applied%20Cryptography_split_035.html#r235" class="calibre5 pcalibre">235</a>].) The unicity distance is
inversely proportional to the redundancy. As redundancy approaches zero,
even a trivial cipher can be unbreakable with a ciphertext-only attack.</p>

<p class="calibre9">Shannon defined a cryptosystem whose unicity distance is infinite as one that
has <b class="calibre10">ideal secrecy</b>. Note that an ideal cryptosystem is not necessarily a perfect cryptosystem, although a perfect cryptosystem would necessarily be an ideal
cryptosystem. If a cryptosystem has ideal secrecy, even successful
cryptanalysis will leave some uncertainty about whether the recovered
plaintext is the real plaintext.</p>

<h4 class="calibre8">Information Theory in Practice</h4>

<p class="calibre9">While these concepts have great theoretical value, actual cryptanalysis seldom
proceeds along these lines. Unicity distance guarantees insecurity if it’s too
small but does not guarantee security if it’s high. Few practical algorithms are
absolutely impervious to analysis; all manner of characteristics might serve as
entering wedges to crack some encrypted messages. However, similar
information theory considerations are occasionally useful, for example, to
determine a recommended key change interval for a particular algorithm.
Cryptanalysts also employ a variety of statistical and information theory tests
to help guide the analysis in the most promising directions. Unfortunately,
most literature on applying information theory to cryptanalysis remains
classified, including the seminal 1940 work of Alan Turing.</p>

<h4 class="calibre8">Confusion and Diffusion</h4>

<p class="calibre9">The two basic techniques for obscuring the redundancies in a plaintext
message are, according to Shannon, confusion and diffusion [<a href="Applied%20Cryptography_split_036.html#r1432" class="calibre5 pcalibre">1432</a>].</p>

<p class="calibre9"><b class="calibre10">Confusion</b> obscures the relationship between the plaintext and the ciphertext.
This frustrates attempts to study the ciphertext looking for redundancies and
statistical patterns. The easiest way to do this is through substitution. A simple
substitution cipher, like the Caesar Cipher, is one in which every identical
letter of plaintext is substituted for a single letter of ciphertext. Modern
substitution ciphers are more complex: A long block of plaintext is substituted
for a different block of ciphertext, and the mechanics of the substitution
change with each bit in the plaintext or key. This type of substitution is not
necessarily enough; the German Enigma is a complex substitution algorithm
that was broken during World War II.</p>

<p class="calibre9"><b class="calibre10">Diffusion</b> dissipates the redundancy of the plaintext by spreading it out over
the ciphertext. A cryptanalyst looking for those redundancies will have a
harder time finding them. The simplest way to cause diffusion is through
transposition (also called <b class="calibre10">permutation</b>). A simple transposition cipher, like
columnar transposition, simply rearranges the letters of the plaintext. Modern
ciphers do this type of permutation, but they also employ other forms of
diffusion that can diffuse parts of the message throughout the entire message.</p>

<p class="calibre9">Stream ciphers rely on confusion alone, although some feedback schemes add
diffusion. Block algorithms use both confusion and diffusion. As a general
rule, diffusion alone is easily cracked (although double transposition ciphers
hold up better than many other pencil-and-paper systems).</p>

<h3 id="11.2" class="calibre7">11.2 Complexity Theory</h3>

<p class="calibre9">Complexity theory provides a methodology for analyzing the <b class="calibre10">computational</b>
<b class="calibre10">complexity</b> of different cryptographic techniques and algorithms. It compares
cryptographic algorithms and techniques and determines their security.
Information theory tells us that all cryptographic algorithms (except one-time
pads) can be broken. Complexity theory tells us whether they can be broken
before the heat death of the universe.</p>

<h4 class="calibre8">Complexity of Algorithms</h4>

<p class="calibre9">An algorithm’s complexity is determined by the computational power needed
to execute it. The computational complexity of an algorithm is often measured
by two variables: <i class="calibre12">T</i> (for <b class="calibre10">time complexity</b>) and <i class="calibre12">S</i> (for <b class="calibre10">space complexity</b>, or memory requirement). Both <i class="calibre12">T</i> and <i class="calibre12">S</i> are commonly expressed as functions of <i class="calibre12">n</i>, where <i class="calibre12">n</i> is the size of the input. (There are other measures of complexity: the number of random bits, the communications bandwidth, the amount of
data, and so on.)</p>

<p class="calibre9">Generally, the computational complexity of an algorithm is expressed in what
is called “big O” notation: the order of magnitude of the computational
complexity. It’s just the term of the complexity function which grows the
fastest as <i class="calibre12">n</i> gets larger; all lower-order terms are ignored. For example, if the time complexity of a given algorithm is 4<i class="calibre12">n<sup class="calibre19">2</sup></i> + 7<i class="calibre12">n</i> + 12, then the computational complexity is on the order of <i class="calibre12">n<sup class="calibre19">2</sup></i>, expressed O(<i class="calibre12">n<sup class="calibre19">2</sup></i>).</p>

<p class="calibre9">Measuring time complexity this way is system-independent. You don’t have to
know the exact timings of various instructions or the number of bits used to
represent different variables or even the speed of the processor. One computer
might be 50 percent faster than another and a third might have a data path
twice as wide, but the order-of-magnitude complexity of an algorithm remains
the same. This isn’t cheating; when you’re dealing with algorithms as complex
as the ones presented here, the other stuff is negligible (is a constant factor)
compared to the order-of-magnitude complexity.</p>

<p class="calibre9">This notation allows you to see how the input size affects the time and space
requirements. For example, if <i class="calibre12">T</i> = O(<i class="calibre12">n</i>), then doubling the input size doubles the running time of the algorithm. If <i class="calibre12">T</i> = O(2<sup class="calibre19"><i class="calibre22">n</i></sup>), then adding one bit to the input size doubles the running time of the algorithm (within a constant factor).</p>

<p class="calibre9">Generally, algorithms are classified according to their time or space
complexities. An algorithm is <b class="calibre10">constant</b> if its complexity is independent of <i class="calibre12">n:</i> O(1). An algorithm is <b class="calibre10">linear</b>, if its time complexity is O(<i class="calibre12">n</i>). Algorithms can also be <b class="calibre10">quadratic</b>, <b class="calibre10">cubic</b>, and so on. All these algorithms are <b class="calibre10">polynomial</b>; their complexity is O(<i class="calibre12">n<sup class="calibre19">m</sup></i>), when <i class="calibre12">m</i> is a constant. The class of algorithms that have a polynomial time complexity are called <b class="calibre10">polynomial-time</b> algorithms.</p>

<p class="calibre9">Algorithms whose complexities are O(<i class="calibre12">t</i><sup class="calibre19"><i class="calibre22">f</i>(<i class="calibre22">n</i>)</sup>), where <i class="calibre12">t</i> is a constant greater than 1
and <i class="calibre12">f</i>(<i class="calibre12">n</i>) is some polynomial function of <i class="calibre12">n</i>, are called <b class="calibre10">exponential</b>. The subset of exponential algorithms whose complexities are O(<i class="calibre12">c</i><sup class="calibre19"><i class="calibre22">f</i>(<i class="calibre22">n</i>)</sup>), where <i class="calibre12">c</i> is a constant and <i class="calibre12">f</i>(<i class="calibre12">n</i>) is more than constant but less than linear, is called <b class="calibre10">superpolynomial</b>.</p>

<p class="calibre9">Ideally, a cryptographer would like to be able to say that the best algorithm to
break this encryption algorithm is of exponential-time complexity. In practice,
the strongest statements that can be made, given the current state of the art of
computational complexity theory, are of the form “all known cracking
algorithms for this cryptosystem are of superpolynomial-time complexity.”
That is, the cracking algorithms that we know are of superpolynomial-time
complexity, but it is not yet possible to prove that no polynomial-time cracking
algorithm could ever be discovered. Advances in computational complexity
may some day make it possible to design algorithms for which the existence of
polynomial-time cracking algorithms can be ruled out with mathematical
certainty.</p>

<p class="calibre9">As <i class="calibre12">n</i> grows, the time complexity of an algorithm can make an enormous
difference in whether the algorithm is practical. Table 11.2 shows the running
times for different algorithm classes in which <i class="calibre12">n</i> equals one million. The table ignores constants, but also shows why ignoring constants is reasonable.</p>

<table class="data-table1" id="table-11-2">
<caption class="calibre23">Table 11.2 - Running Times of Different Classes of Algorithms</caption>
<tbody class="calibre24"><tr class="calibre25">
<th class="calibre26">Class</th>
<th class="calibre26">Complexity</th>
<th class="calibre26"># of Operations for <i class="calibre12">n</i> = 10<sup class="calibre47">6</sup></th>
<th class="calibre26">Time at 10<sup class="calibre47">6</sup> O/S</th>
</tr>
<tr class="calibre25"><td class="calibre64">Constant</td><td class="calibre64">O(1)</td><td class="calibre64">1</td><td class="calibre64">1 µsec.</td></tr>
<tr class="calibre25"><td class="calibre64">Linear</td><td class="calibre64">O(<i class="calibre12">n</i>)</td><td class="calibre64">10<sup class="calibre47">6</sup></td><td class="calibre64">1 sec.</td></tr>
<tr class="calibre25"><td class="calibre64">Quadratic</td><td class="calibre64">O(<i class="calibre12">n<sup class="calibre47">2</sup></i>)</td><td class="calibre64">10<sup class="calibre47">12</sup></td><td class="calibre64">11.6 days</td></tr>
<tr class="calibre25"><td class="calibre64">Cubic</td><td class="calibre64">O(<i class="calibre12">n<sup class="calibre47">3</sup></i>)</td><td class="calibre64">10<sup class="calibre47">18</sup></td><td class="calibre64">32,000 yrs.</td></tr>
<tr class="calibre25"><td class="calibre65">Exponential</td><td class="calibre65">O(2<sup class="calibre47">n</sup>)</td><td class="calibre65">10<sup class="calibre47">301,030</sup></td><td class="calibre65">10<sup class="calibre47">301,006</sup> times the age of the universe</td></tr>
</tbody></table>

<p class="calibre39">Assuming that the unit of “time” for our computer is a microsecond, the
computer can complete a constant algorithm in a microsecond, a linear
algorithm in a second, and a quadratic algorithm in 11.6 days. It would take
32,000 years to complete a cubic algorithm; not terribly practical, but a
computer built to withstand the next ice age would deliver a solution
eventually. Performing the exponential algorithm is futile, no matter how well
you extrapolate computing power, parallel processing, or contact with
superintelligent aliens.</p>

<p class="calibre9">Look at the problem of a brute-force attack against an encryption algorithm.
The time complexity of this attack is proportional to the number of possible
keys, which is an exponential function of the key length. If <i class="calibre12">n</i> is the length of the key, then the complexity of a brute-force attack is O(2<sup class="calibre19"><i class="calibre22">n</i></sup>). <a href="Applied%20Cryptography_split_015.html#12.3" class="calibre5 pcalibre">Section 12.3</a>
discusses the controversy surrounding a 56-bit key for DES instead of a
112-bit key. The complexity of a brute-force attack against a 56-bit key is 2<sup class="calibre19">56</sup>;
against a 112-bit key the complexity is 2<sup class="calibre19">112</sup>. The former is possible; the latter
isn’t.</p>

<h4 class="calibre8">Complexity of Problems</h4>

<p class="calibre9">Complexity theory also classifies the inherent complexity of problems, not just
the complexity of particular algorithms used to solve problems. (Excellent
introductions to this topic are [<a href="Applied%20Cryptography_split_035.html#r600" class="calibre5 pcalibre">600</a>,<a href="Applied%20Cryptography_split_035.html#r211" class="calibre5 pcalibre">211</a>,<a href="Applied%20Cryptography_split_036.html#r1226" class="calibre5 pcalibre">1226</a>]; see also [<a href="Applied%20Cryptography_split_036.html#r1096" class="calibre5 pcalibre">1096</a>,<a href="Applied%20Cryptography_split_035.html#r27" class="calibre5 pcalibre">27</a>,<a href="Applied%20Cryptography_split_035.html#r739" class="calibre5 pcalibre">739</a>].) The
theory looks at the minimum time and space required to solve the hardest
instance of a problem on a theoretical computer known as a <b class="calibre10">Turing machine</b> .
A Turing machine is a finite-state machine with an infinite read-write memory
tape. It turns out that a Turing machine is a realistic model of computation.</p>

<p class="calibre9">Problems that can be solved with polynomial-time algorithms are called
<b class="calibre10">tractable</b>, because they can usually be solved in a reasonable amount of time
for reasonable-sized inputs. (The exact definition of “reasonable” depends on
the circumstance.) Problems that cannot be solved in polynomial time are
called <b class="calibre10">intractable</b>, because calculating their solution quickly becomes
infeasible. Intractable problems are sometimes just called <b class="calibre10">hard</b>. Problems that
can only be solved with algorithms that are superpolynomial are
computationally intractable, even for relatively small values of <i class="calibre12">n</i>.</p>

<p class="calibre9">It gets worse. Alan Turing proved that some problems are <b class="calibre10">undecidable</b>. It is
impossible to devise any algorithm to solve them, regardless of the algorithm’s
time complexity.</p>

<p class="calibre9">Problems can be divided into complexity classes, which depend on the
complexity of their solutions. Figure 11.1 shows the more important
complexity classes and their presumed relationships. (Unfortunately, not much
about this material has been proved mathematically.)</p>

<div class="figure" id="figure-11-1">
<div class="image1">
<p class="calibre9"><img src="ac-figure-11-1.png" class="calibre11"/></p>
</div>
<p class="calibre9"><i class="calibre12"><b class="calibre10">Figure 11.1</b> Complexity classes.</i></p>
</div>

<p class="calibre9">On the bottom, the class <b class="calibre10">P</b> consists of all problems that can be solved in
polynomial time. The class <b class="calibre10">NP</b> consists of all problems that can be solved in
polynomial time only on a nondeterministic Turing machine: a variant of a
normal Turing machine that can make guesses. The machine guesses the
solution to the problem — either by making “lucky guesses” or by trying all
guesses in parallel — and checks its guess in polynomial time.</p>

<p class="calibre9"><b class="calibre10">NP</b> ’s relevance to cryptography is this: Many symmetric algorithms and all
public-key algorithms can be cracked in nondeterministic polynomial time.
Given a ciphertext <i class="calibre12">C</i>, the cryptanalyst simply guesses a plaintext, <i class="calibre12">X</i>, and a key, <i class="calibre12">k</i>, and in polynomial time runs the encryption algorithm on inputs <i class="calibre12">X</i> and <i class="calibre12">k</i> and checks whether the result is equal to <i class="calibre12">C</i>. This is important theoretically, because it puts an upper bound on the complexity of cryptanalysis for these algorithms.
In practice, of course, it is a deterministic polynomial-time algorithm that the
cryptanalyst seeks. Furthermore, this argument is not applicable to all classes
of ciphers; in particular, it is not applicable to one-time pads — for any <i class="calibre12">C</i>, there are many <i class="calibre12">X, k</i> pairs that yield <i class="calibre12">C</i> when run through the encryption algorithm, but most of these <i class="calibre12">X</i> s are nonsense, not legitimate plaintexts.</p>

<p class="calibre9">The class <b class="calibre10">NP</b> includes the class <b class="calibre10">P</b>, because any problem solvable in
polynomial time on a deterministic Turing machine is also solvable in
polynomial time on a nondeterministic Turing machine; the guessing stage can
simply be omitted.</p>

<p class="calibre9">If all <b class="calibre10">NP</b> problems are solvable in polynomial time on a deterministic machine,
then <b class="calibre10">P</b> = <b class="calibre10">NP</b>. Although it seems obvious that some <b class="calibre10">NP</b> problems are much harder than others (a brute-force attack against an encryption algorithm versus
encrypting a random block of plaintext), it has never been proven that <b class="calibre10">P</b> ≠ <b class="calibre10">NP</b>
(or that <b class="calibre10">P</b> = <b class="calibre10">NP</b>). However, most people working in complexity theory believe that they are unequal.</p>

<p class="calibre9">Stranger still, specific problems in <b class="calibre10">NP</b> can be proven to be as difficult as any problem in the class. Steven Cook [<a href="Applied%20Cryptography_split_035.html#r365" class="calibre5 pcalibre">365</a>] proved that the Satisfiability problem
(given a propositional Boolean formula, is there a way to assign truth values to
the variables that makes the formula true?) is <b class="calibre10">NP-complete</b> . This means that,
if Satisfiability is solvable in polynomial time, then <b class="calibre10">P</b> = <b class="calibre10">NP</b>. Conversely, if any problem in <b class="calibre10">NP</b> can be proven not to have a deterministic polynomial-time
algorithm, the proof will show that Satisfiability does not have a deterministic
polynomial-time algorithm either. No problem is harder than Satisfiability in
<b class="calibre10">NP</b>.</p>

<p class="calibre9">Since Cook’s seminal paper was published, a huge number of problems have
been shown to be equivalent to Satisfiability; hundreds are listed in [<a href="Applied%20Cryptography_split_035.html#r600" class="calibre5 pcalibre">600</a>], and
some examples follow. By equivalent, I mean that these problems are also
<b class="calibre10">NP-complete</b>; they are in <b class="calibre10">NP</b> and also as hard as any problem in <b class="calibre10">NP</b> . If their solvability in deterministic polynomial time were resolved, the <b class="calibre10">P</b> versus <b class="calibre10">NP</b>
question would be solved. The question of whether <b class="calibre10">P</b> = <b class="calibre10">NP</b> is the central
unsolved question of computational complexity theory, and no one expects it
to be solved anytime soon. If someone showed that <b class="calibre10">P</b> = <b class="calibre10">NP</b>, then most of this book would be irrelevant: As previously explained, many classes of ciphers are
trivially breakable in nondeterministic polynomial time. If <b class="calibre10">P</b> = <b class="calibre10">NP</b>, they are breakable by feasible, deterministic algorithms.</p>

<p class="calibre9">Further out in the complexity hierarchy is <b class="calibre10">PSPACE</b> . Problems in <b class="calibre10">PSPACE</b>
can be solved in polynomial space, but not necessarily polynomial time.
<b class="calibre10">PSPACE</b> includes <b class="calibre10">NP</b>, but some problems in <b class="calibre10">PSPACE</b> are thought to be harder than <b class="calibre10">NP</b>. Of course, this isn’t proven either. There is a class of
problems, the so-called <b class="calibre10">PSPACE-complete</b> problems, with the property that,
if any one of them is in <b class="calibre10">NP</b> then <b class="calibre10">PSPACE</b> = <b class="calibre10">NP</b> and if any one of them is in <b class="calibre10">P</b>
then <b class="calibre10">PSPACE</b> = <b class="calibre10">P</b> .</p>

<p class="calibre9">And finally, there is the class of problems called <b class="calibre10">EXPTIME</b> . These problems
are solvable in exponential time. The <b class="calibre10">EXPTIME-complete</b> problems can
actually be proven not to be solvable in deterministic polynomial time. It has
been shown that <b class="calibre10">P</b> does not equal <b class="calibre10">EXPTIME</b> .</p>

<h4 class="calibre8">NP-Complete Problems</h4>

<p class="calibre9">Michael Garey and David Johnson compiled a list of over 300 <b class="calibre10">NP-complete</b>
<b class="calibre10">problems</b> [<a href="Applied%20Cryptography_split_035.html#r600" class="calibre5 pcalibre">600</a>]. Here are just a few of them:</p>

<ul class="calibre13">

<li class="calibre14">Traveling Salesman Problem. A traveling salesman has to visit <i class="calibre12">n</i>
different cities using only one tank of gas (there is a maximum distance
he can travel). Is there a route that allows him to visit each city exactly
once on that single tank of gas? (This is a generalization of the
Hamiltonian Cycle problem — see <a href="Applied%20Cryptography_split_006.html#5.1" class="calibre5 pcalibre">Section 5.1</a>.)
</li>
<li class="calibre14">Three-Way Marriage Problem. In a room are <i class="calibre12">n</i> men, <i class="calibre12">n</i> women, and <i class="calibre12">n</i>
clergymen (priests, rabbis, whatever). There is also a list of acceptable
marriages, which consists of one man, one woman, and one clergyman
willing to officiate. Given this list of possible triples, is it possible to
arrange <i class="calibre12">n</i> marriages such that everyone is either marrying one person or
officiating at one marriage?
</li>
<li class="calibre14">Three-Satisfiability. There is a list of <i class="calibre12">n</i> logical statements, each with
three variables. For example: if (<i class="calibre12">x</i> and <i class="calibre12">y</i>) then <i class="calibre12">z</i>, (<i class="calibre12">x</i> and <i class="calibre12">w</i>) or (not <i class="calibre12">z</i>), if ((not <i class="calibre12">u</i> and not <i class="calibre12">x</i>) or (<i class="calibre12">z</i> and (<i class="calibre12">u</i> or not <i class="calibre12">x</i>))) then (not <i class="calibre12">z</i> and <i class="calibre12">u</i>) or <i class="calibre12">x</i>), and so on. Is there a truth assignment for all the variables that satisfies all the
statements? (This is a special case of the Satisfiability problem
previously mentioned.)
</li>

</ul>

<h3 id="11.3" class="calibre7">11.3 Number Theory</h3>

<p class="calibre9">This isn’t a book on number theory, so I’m just going to sketch a few ideas
that apply to cryptography. If you want a detailed mathematical text on
number theory, consult one of these books: [<a href="Applied%20Cryptography_split_036.html#r1430" class="calibre5 pcalibre">1430</a>,<a href="Applied%20Cryptography_split_035.html#r72" class="calibre5 pcalibre">72</a>,<a href="Applied%20Cryptography_split_036.html#r1171" class="calibre5 pcalibre">1171</a>,<a href="Applied%20Cryptography_split_035.html#r12" class="calibre5 pcalibre">12</a>,<a href="Applied%20Cryptography_split_036.html#r959" class="calibre5 pcalibre">959</a>,<a href="Applied%20Cryptography_split_035.html#r681" class="calibre5 pcalibre">681</a>,<a href="Applied%20Cryptography_split_035.html#r742" class="calibre5 pcalibre">742</a>,<a href="Applied%20Cryptography_split_035.html#r420" class="calibre5 pcalibre">420</a>]. 
My two favorite books on the mathematics of finite fields are [<a href="Applied%20Cryptography_split_036.html#r971" class="calibre5 pcalibre">971</a>,<a href="Applied%20Cryptography_split_036.html#r1042" class="calibre5 pcalibre">1042</a>]. 
See also [<a href="Applied%20Cryptography_split_035.html#r88" class="calibre5 pcalibre">88</a>,<a href="Applied%20Cryptography_split_036.html#r1157" class="calibre5 pcalibre">1157</a>,<a href="Applied%20Cryptography_split_036.html#r1158" class="calibre5 pcalibre">1158</a>,<a href="Applied%20Cryptography_split_036.html#r1060" class="calibre5 pcalibre">1060</a>].</p>

<h4 class="calibre8">Modular Arithmetic</h4>

<p class="calibre9">You all learned modular arithmetic in school; it was called “clock arithmetic.”
Remember these word problems? If Mildred says she’ll be home by 10:00, and
she’s 13 hours late, what time does she get home and for how many years does
her father ground her? That’s arithmetic modulo 12. Twenty-three modulo 12
equals 11.</p>

<p class="math">(10 + 13) mod 12 = 23 mod 12 = 11 mod 12
</p>

<p class="calibre9">Another way of writing this is to say that 23 and 11 are equivalent, modulo 12:</p>

<p class="math">23 ≡ 11 (mod 12)
</p>

<p class="calibre9">Basically, <i class="calibre12">a</i> ≡ <i class="calibre12">b</i> (mod <i class="calibre12">n</i>) if <i class="calibre12">a</i> = <i class="calibre12">b</i> + <i class="calibre12">kn</i> for some integer <i class="calibre12">k. </i> If <i class="calibre12">a</i> is non-negative and <i class="calibre12">b</i> is between 0 and <i class="calibre12">n</i>, you can think of <i class="calibre12">b</i> as the remainder of <i class="calibre12">a</i> when divided by <i class="calibre12">n. </i> Sometimes, <i class="calibre12">b</i> is called the <b class="calibre10">residue</b> of <i class="calibre12">a</i>, modulo <i class="calibre12">n. </i> Sometimes <i class="calibre12">a</i> is called <b class="calibre10">congruent</b> to <i class="calibre12">b</i>, modulo <i class="calibre12">n</i> (the triple equals sign, ≡, denotes congruence). These are just different ways of saying the same thing.</p>

<p class="calibre9">The set of integers from 0 to <i class="calibre12">n</i> - 1 form what is called a <b class="calibre10">complete set of residues</b> modulo <i class="calibre12">n.</i> This means
that, for every integer <i class="calibre12">a</i>, its residue modulo <i class="calibre12">n</i> is some number from 0 to <i class="calibre12">n</i> - 1.</p>

<p class="calibre9">The operation <i class="calibre12">a</i> mod <i class="calibre12">n</i> denotes the residue of <i class="calibre12">a</i>, such that the residue is some integer from 0 to <i class="calibre12">n</i> - 1. This operation is <b class="calibre10">modular reduction</b>. For example, 5 mod 3 = 2.</p>

<p class="calibre9">This definition of mod may be different from the definition used in some
programming languages. For example, PASCAL’s modulo operator sometimes
returns a negative number. It returns a number between -(<i class="calibre12">n</i> - 1) and <i class="calibre12">n</i> - 1. In C, the % operator returns the remainder from the division of the first expression
by the second; this can be a negative number if either operand is negative. For
all the algorithms in this book, make sure you add <i class="calibre12">n</i> to the result of the modulo operator if it returns a negative number.</p>

<p class="calibre9">Modular arithmetic is just like normal arithmetic: It’s commutative,
associative, and distributive. Also, reducing each intermediate result modulo <i class="calibre12">n</i>
yields the same result as doing the whole calculation and then reducing the end
result modulo <i class="calibre12">n</i>.</p>

<p class="math">(<i class="calibre12">a</i> + <i class="calibre12">b</i>) mod <i class="calibre12">n</i> = ((<i class="calibre12">a</i> mod <i class="calibre12">n</i>) + (<i class="calibre12">b</i> mod <i class="calibre12">n</i>)) mod <i class="calibre12">n</i>
(<i class="calibre12">a</i> - <i class="calibre12">b</i>) mod <i class="calibre12">n</i> = ((<i class="calibre12">a</i> mod <i class="calibre12">n</i>) - (<i class="calibre12">b</i> mod <i class="calibre12">n</i>)) mod <i class="calibre12">n</i>
(<i class="calibre12">a*b</i>) mod <i class="calibre12">n</i> = ((<i class="calibre12">a</i> mod <i class="calibre12">n</i>)*(<i class="calibre12">b</i> mod <i class="calibre12">n</i>)) mod <i class="calibre12">n</i>
(<i class="calibre12">a</i>*(<i class="calibre12">b</i> + c)) mod <i class="calibre12">n</i> = (((<i class="calibre12">a*b</i>) mod <i class="calibre12">n</i>) + ((<i class="calibre12">a*c</i>) mod <i class="calibre12">n</i>)) mod <i class="calibre12">n</i>
</p>

<p class="calibre9">Cryptography uses computation mod <i class="calibre12">n</i> a lot, because calculating discrete
logarithms and square roots mod <i class="calibre12">n</i> can be hard problems. Modular arithmetic
is also easier to work with on computers, because it restricts the range of all
intermediate values and the result. For a <i class="calibre12">k-</i>bit modulus, <i class="calibre12">n</i>, the intermediate results of any addition, subtraction, or multiplication will not be more than 2<i class="calibre12">k</i>-bits long. So we can perform exponentiation in modular arithmetic without
generating huge intermediate results. Calculating the power of some number
modulo some number,</p>

<p class="math"><i class="calibre12">a<sup class="calibre19">x</sup></i> mod <i class="calibre12">n</i>,
</p>

<p class="calibre9">is just a series of multiplications and divisions, but there are speedups. One
kind of speedup aims to minimize the number of modular multiplications;
another kind aims to optimize the individual modular multiplications. Because
the operations are distributive, it is faster to do the exponentiation as a stream
of successive multiplications, taking the modulus every time. It doesn’t make
much difference now, but it will when you’re working with 200-bit numbers.</p>

<p class="calibre9">For example, if you want to calculate <i class="calibre12">a<sup class="calibre19">8</sup></i> mod <i class="calibre12">n</i>, don’t use the naïve approach and perform seven multiplications and one huge modular reduction:</p>

<p class="math">(<i class="calibre12">a*a*a*a*a*a*a*a</i>) mod <i class="calibre12">n</i>
</p>

<p class="calibre9">Instead, perform three smaller multiplications and three smaller modular
reductions:</p>

<p class="math">((<i class="calibre12">a<sup class="calibre19">2</sup></i> mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>
</p>

<p class="calibre9">By the same token,</p>

<p class="math"><i class="calibre12">a<sup class="calibre19">16</sup></i> mod <i class="calibre12">n</i> = (((<i class="calibre12">a<sup class="calibre19">2</sup></i> mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>
</p>

<p class="calibre9">Computing <i class="calibre12">a<sup class="calibre19">x</sup></i> mod <i class="calibre12">n</i>, where <i class="calibre12">x</i> is not a power of 2, is only slightly harder. Binary notation expresses <i class="calibre12">x</i> as a sum of powers of 2: 25 is 11001 in binary, so 2<sup class="calibre19">5</sup> = 2<sup class="calibre19">4</sup> + 2<sup class="calibre19">3</sup> + 2<sup class="calibre19">0</sup>. So</p>

<p class="math"><i class="calibre12">a<sup class="calibre19">25</sup></i> mod <i class="calibre12">n</i>
= (<i class="calibre12">a*a<sup class="calibre19">24</sup></i>) mod <i class="calibre12">n</i>
= (<i class="calibre12">a*a<sup class="calibre19">8</sup>*a<sup class="calibre19">16</sup></i>) mod <i class="calibre12">n</i>
= (<i class="calibre12">a</i>*((<i class="calibre12">a<sup class="calibre19">2</sup></i>)<sup class="calibre19">2</sup>)<sup class="calibre19">2</sup>*(((<i class="calibre12">a<sup class="calibre19">2</sup></i>)<sup class="calibre19">2</sup>)<sup class="calibre19">2</sup>)<sup class="calibre19">2</sup>) mod <i class="calibre12">n</i>
= ((((<i class="calibre12">a<sup class="calibre19">2</sup>*a</i>)<sup class="calibre19">2</sup>)<sup class="calibre19">2</sup>)<sup class="calibre19">2</sup>*<i class="calibre12">a</i>) mod <i class="calibre12">n</i>
</p>

<p class="calibre9">With judicious storing of intermediate results, you only need six multiplications:</p>

<p class="math">(((((((<i class="calibre12">a<sup class="calibre19">2</sup></i> mod <i class="calibre12">n</i>)*<i class="calibre12">a</i>) mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>)<sup class="calibre19">2</sup> mod <i class="calibre12">n</i>)*<i class="calibre12">a</i>) mod <i class="calibre12">n</i>
</p>

<p class="calibre9">This is called <b class="calibre10">addition chaining</b> [<a href="Applied%20Cryptography_split_036.html#r863" class="calibre5 pcalibre">863</a>], or the binary square and multiply method. It uses a simple and obvious addition chain based on the binary representation. In C, it looks like:</p>

<pre class="calibre20">unsigned long qe2(unsigned long x, unsigned long y, unsigned long n) {
    unsigned long s,t,u;
    int i;

    s = 1; t = x; u = y;
    while(u) {
        if(u&amp;1) s = (s*t)%n;
        u&gt;&gt;=1;
        t = (t*t)%n;
    }
    return(s);
}
</pre>

<p class="calibre9">Another, recursive, algorithm is:</p>

<pre class="calibre20">unsigned long fast_exp(unsigned long x, unsigned long y, unsigned long N) {
    unsigned long tmp;

    if(y==1) return(x % N);
    if ((y&amp;1)==0) {
        tmp = fast_exp(x,y/2,N);
        return ((tmp*tmp)%N);
    }
    else {
        tmp = fast_exp(x,(y-1)/2,N);
        tmp = (tmp*tmp)%N;
        tmp = (tmp*x)%N;
        return (tmp);
    }
}
</pre>

<p class="calibre9">This technique reduces the operation to, on the average, 1.5*<i class="calibre12">k</i> operations, if <i class="calibre12">k</i><sub class="calibre15">i</sub>s the length of the number <i class="calibre12">x</i> in bits.
Finding the calculation with the fewest operations is a hard problem (it has been proven that the sequence must contain at least <i class="calibre12">k</i>-1 operations), but it is not too hard to get the number of operations down to 1.1*<i class="calibre12">k</i> or better, as <i class="calibre12">k</i> grows.</p>

<p class="calibre9">An efficient way to do modular reductions many times using the same <i class="calibre12">n</i> is <b class="calibre10">Montgomery’s method</b> [<a href="Applied%20Cryptography_split_036.html#r1111" class="calibre5 pcalibre">1111</a>]. Another method is called <b class="calibre10">Barrett’s algorithm</b> [<a href="Applied%20Cryptography_split_035.html#r87" class="calibre5 pcalibre">87</a>]. The software performance of these two algorithms and the algorithm previously discussed is in [<a href="Applied%20Cryptography_split_035.html#r210" class="calibre5 pcalibre">210</a>]: The algorithm I’ve discussed is the best choice for singular modular reductions; Barrett’s algorithm is the best choice for small arguments; and Montgomery’s method is the best choice for general modular exponentiations. (Montgomery’s method can also take advantage of small exponents, using something called mixed arithmetic.)</p>

<p class="calibre9">The inverse of exponentiation modulo <i class="calibre12">n</i> is calculating a <b class="calibre10">discrete logarithm</b>. I’ll discuss this shortly.</p>

<h4 class="calibre8">Prime Numbers</h4>

<p class="calibre9">A <b class="calibre10">prime</b> number is an integer greater than 1 whose only factors are 1 and itself: No other number evenly divides it.
Two is a prime number. So are 73, 2521, 2365347734339, and 2<sup class="calibre19">756839</sup> - 1. There are an infinite number of primes.
Cryptography, especially public-key cryptography, uses large primes (512 bits and even larger) often.</p>

<p class="calibre9">Evangelos Kranakis wrote an excellent book on number theory, prime numbers, and their applications to cryptography [<a href="Applied%20Cryptography_split_036.html#r896" class="calibre5 pcalibre">896</a>]. Paulo Ribenboim wrote two excellent references on prime numbers in general [<a href="Applied%20Cryptography_split_036.html#r1307" class="calibre5 pcalibre">1307</a>,<a href="Applied%20Cryptography_split_036.html#r1308" class="calibre5 pcalibre">1308</a>].</p>

<h4 class="calibre8">Greatest Common Divisor</h4>

<p class="calibre9">Two numbers are <b class="calibre10">relatively prime</b> when they share no factors in common other than 1. In other words, if the <b class="calibre10">greatest</b> <b class="calibre10">common divisor</b> of <i class="calibre12">a</i> and <i class="calibre12">n</i> is equal to 1. This is written:</p>

<p class="math">gcd(<i class="calibre12">a,n</i>) = 1
</p>

<p class="calibre9">The numbers 15 and 28 are relatively prime, 15 and 27 are not, and 13 and 500 are. A prime number is relatively prime to all other numbers except its multiples.</p>

<p class="calibre9">One way to compute the greatest common divisor of two numbers is with <b class="calibre10">Euclid’s algorithm</b>. Euclid described the algorithm in his book, <i class="calibre12">Elements</i>, written around 300 B.C. He didn’t invent it. Historians believe the algorithm could be 200 years older. It is the oldest nontrivial algorithm that has survived to the present day, and it is still a good one.
Knuth describes the algorithm and some modern modifications [<a href="Applied%20Cryptography_split_036.html#r863" class="calibre5 pcalibre">863</a>].</p>

<p class="calibre9">In C:</p>

<pre class="calibre20">/* returns gcd of x and y */
int gcd (int x, int y)
{
    int g;

    if (x &lt; 0)
        x = -x;
    if (y &lt; 0)
        y = -y;
    if (x + y == 0)
        ERROR;
    g = y;
    while (x &gt; 0) {
        g = x;
        x = y % x;
        y = g;
    }
    return g;
}
</pre>

<p class="calibre9">This algorithm can be generalized to return the gcd of an array of <i class="calibre12">m</i> numbers:</p>

<pre class="calibre20">/* returns the gcd of x1, x2...xm */
int multiple_gcd (int m, int *x)
{
    size_t i;
    int g;

    if (m &lt; 1)
        return 0;
    g = x[0];
    for (i=1; i&lt;m; ++i) {
        g = gcd(g, x[i]);
        /* optimization, since for random x[i], g==1 60% of the time: */
        if (g == 1)
        return 1;
    }
    return g;
}
</pre>

<h4 class="calibre8">Inverses Modulo a Number</h4>

<p class="calibre9">Remember inverses? The multiplicative inverse of 4 is 1/4, because 4*1/4 = 1. In the modulo world, the problem is more complicated:</p>

<p class="math">4*<i class="calibre12">x</i> ≡ 1 (mod 7)
</p>

<p class="calibre9">This equation is equivalent to finding an <i class="calibre12">x</i> and <i class="calibre12">k</i> such that</p>

<p class="math">4<i class="calibre12">x</i> = 7<i class="calibre12">k</i> + 1
</p>

<p class="calibre9">where both <i class="calibre12">x</i> and <i class="calibre12">k</i> are integers.</p>

<p class="calibre9">The general problem is finding an <i class="calibre12">x</i> such that</p>

<p class="math">1 = (<i class="calibre12">a*x</i>) mod <i class="calibre12">n</i>
</p>

<p class="calibre9">This is also written as</p>

<p class="math"><i class="calibre12">a</i><sup class="calibre19">-1</sup> ≡ <i class="calibre12">x</i> (mod <i class="calibre12">n</i>)
</p>

<p class="calibre9">The modular inverse problem is a lot more difficult to solve. Sometimes it has a solution, sometimes not. For example, the inverse of 5, modulo 14, is 3. On the other hand, 2 has no inverse modulo 14.</p>

<p class="calibre9">In general, <i class="calibre12">a</i><sup class="calibre19">-1</sup> ≡ <i class="calibre12">x</i> (mod <i class="calibre12">n</i>) has a unique solution if <i class="calibre12">a</i> and <i class="calibre12">n</i> are relatively prime. If <i class="calibre12">a</i> and <i class="calibre12">n</i> are not relatively prime, then <i class="calibre12">a</i><sup class="calibre19">-1</sup> ≡ <i class="calibre12">x</i> (mod <i class="calibre12">n</i>) has no solution. If <i class="calibre12">n</i> is a prime number, then every number from 1 to <i class="calibre12">n</i> - 1 is relatively prime to <i class="calibre12">n</i> and has exactly one inverse modulo <i class="calibre12">n</i> in that range.</p>

<p class="calibre9">So far, so good. Now, how do you go about finding the inverse of <i class="calibre12">a</i> modulo <i class="calibre12">n</i>? There are a couple of ways. Euclid’s algorithm can also compute the inverse of a number modulo <i class="calibre12">n. </i>
Sometimes this is called the <b class="calibre10">extended Euclidean algorithm</b>.</p>

<p class="calibre9">Here’s the algorithm in C++:</p>

<pre class="calibre20">#define isEven(x)   ((x &amp; 0x01) == 0)
#define isOdd(x)    (x &amp; 0x01)
#define swap(x,y)   (x ^= y, y ^= x, x ^= y)

void ExtBinEuclid(int *u, int *v, int *u1, int *u2, int *u3)
{
    // warning: u and v will be swapped if u &lt; v
    int k, t1, t2, t3;

    if (*u &lt; *v) swap(*u,*v);
    for (k = 0; isEven(*u) &amp;&amp; isEven(*v); ++k) {
        *u &gt;&gt;= 1; *v &gt;&gt;= 1;
    }
    *u1 = 1; *u2 = 0; *u3 = *u; t1 = *v; t2 = *u-1; t3 = *v;
    do {
        do {
            if (isEven(*u3)) {
                if (isOdd(*u1) || isOdd(*u2)) {
                    *u1 += *v; *u2 += *u;
                }
                *u1 &gt;&gt;= 1; *u2 &gt;&gt;= 1; *u3 &gt;&gt;= 1;
            }
            if (isEven(t3) || *u3 &lt; t3) {
                swap(*u1,t1); swap(*u2,t2); swap(*u3,t3);
            }
        } while (isEven(*u3));
        while (*u1 &lt; t1 || *u2 &lt; t2) {
            *u1 += *v; *u2 += *u;
        }
        *u1 -= t1; *u2 -= t2; *u3 -= t3;
    } while (t3 &gt; 0);
    while (*u1 &gt;= *v &amp;&amp; *u2 &gt;= *u) {
        *u1 -= *v; *u2 -= *u;
    }
    *u1 &lt;&lt;= k; *u2 &lt;&lt;= k; *u3 &lt;&lt;= k;
}

main(int argc, char **argv) {
    int a, b, gcd;

    if (argc &lt; 3) {
        cerr &lt;&lt; "Usage: xeuclid u v" &lt;&lt; endl;
        return -1;
    }
    int u = atoi(argv[1]);
    int v = atoi(argv[2]);
    if (u &lt;= 0 || v &lt;= 0) {
        cerr &lt;&lt; "Arguments must be positive!" &lt;&lt; endl;
        return -2;
    }
    // warning: u and v will be swapped if u &lt; v
    ExtBinEuclid(&amp;u, &amp;v, &amp;a, &amp;b, &amp;gcd);
    cout &lt;&lt; a &lt;&lt; " * " &lt;&lt; u &lt;&lt; " + (-"
         &lt;&lt; b &lt;&lt; ") * " &lt;&lt; v &lt;&lt; " = " &lt;&lt; gcd &lt;&lt; endl;
    if (gcd == 1)
        cout &lt;&lt; "the inverse of " &lt;&lt; v &lt;&lt; " mod " &lt;&lt; u &lt;&lt; " is: "
             &lt;&lt; u - b &lt;&lt; endl;
    return 0;
}
</pre>

<p class="calibre9">I’m not going to prove that it works or give the theory behind it. Details can be found in [<a href="Applied%20Cryptography_split_036.html#r863" class="calibre5 pcalibre">863</a>], or in any of the number theory texts previously listed.</p>

<p class="calibre9">The algorithm is iterative and can be slow for large numbers. Knuth showed that the average number of divisions performed by the algorithm is:</p>

<p class="math">.843*log<sub class="calibre15">2</sub>(<i class="calibre12">n</i>) + 1.47
</p>

<h4 class="calibre8">Solving for Coefficients</h4>

<p class="calibre9">Euclid’s algorithm can be used to solve this class of problems: Given an array of <i class="calibre12">m</i> variables <i class="calibre12">x</i><sub class="calibre15">1</sub>,
<i class="calibre12">x</i><sub class="calibre15">2</sub>, ... <i class="calibre12">x<sub class="calibre15">m</sub></i>, find an array of <i class="calibre12">m</i> coefficients, <i class="calibre12">u</i><sub class="calibre15">1</sub>, <i class="calibre12">u</i><sub class="calibre15">2</sub>, ... <i class="calibre12">u<sub class="calibre15">m</sub></i>, such that</p>

<p class="math"><i class="calibre12">u</i><sub class="calibre15">1</sub> * <i class="calibre12">x</i><sub class="calibre15">1</sub> + ... + <i class="calibre12">u<sub class="calibre15">m</sub></i> * <i class="calibre12">x<sub class="calibre15">m</sub></i> = 1
</p>

<h4 class="calibre8">Fermat’s Little Theorem</h4>

<p class="calibre9">If <i class="calibre12">m</i> is a prime, and <i class="calibre12">a</i> is not a multiple of <i class="calibre12">m</i>, then <b class="calibre10">Fermat’s little theorem</b> says</p>

<p class="math"><i class="calibre12">a</i><sup class="calibre19"><i class="calibre22">m</i>-1</sup> ≡ 1 (mod <i class="calibre12">m</i>)
</p>

<p class="calibre9">(Pierre de Fermat, pronounced “Fair-ma, ” was a French mathematician who lived from 1601 to 1665. This theorem has nothing to do with his last theorem.)</p>

<h4 class="calibre8">The Euler Totient Function</h4>

<p class="calibre9">There is another method for calculating the inverse modulo <i class="calibre12">n</i>, but it’s not always possible to use it. The <b class="calibre10">reduced set of residues</b> mod <i class="calibre12">n</i> is the subset of the complete set of residues that is relatively prime to <i class="calibre12">n. </i> For example, the reduced set of residues mod 12 is {1, 5, 7, 11}. If <i class="calibre12">n</i> is prime, then the reduced set of residues mod <i class="calibre12">n</i> is the set of all numbers from 1 to <i class="calibre12">n</i> - 1. The number 0 is never part of the reduced set of residues for any <i class="calibre12">n</i> not equal to 1.</p>

<p class="calibre9">The <b class="calibre10">Euler totient function</b>, also called the Euler phi function and written as φ(<i class="calibre12">n</i>), is the number of elements in the reduced set of residues modulo <i class="calibre12">n. </i> In other words, φ(<i class="calibre12">n</i>) is the number of positive integers less than <i class="calibre12">n</i> that are relatively prime to <i class="calibre12">n</i> (for any <i class="calibre12">n</i> greater than 1). (Leonhard Euler, pronounced “Oiler, ” was a Swiss mathematician who lived from 1707 to 1783.)</p>

<p class="calibre9">If <i class="calibre12">n</i> is prime, then φ(<i class="calibre12">n</i>) = <i class="calibre12">n</i> - 1. If <i class="calibre12">n</i> = <i class="calibre12">pq</i>, where <i class="calibre12">p</i> and <i class="calibre12">q</i> are prime, then φ(<i class="calibre12">n</i>) = (<i class="calibre12">p</i> - 1)(<i class="calibre12">q</i> - 1).
These numbers appear in some public-key algorithms; this is why.</p>

<p class="calibre9">According to <b class="calibre10">Euler’s generalization of Fermat’s little theorem</b>, if gcd(<i class="calibre12">a,n</i>) = 1, then</p>

<p class="math"><i class="calibre12">a</i><sup class="calibre19"><i class="calibre22">φ</i>(<i class="calibre22">n</i>)</sup> mod <i class="calibre12">n</i> = 1
</p>

<p class="calibre9">Now it is easy to compute <i class="calibre12">a</i><sup class="calibre19">-1</sup> mod <i class="calibre12">n:</i></p>

<p class="math"><i class="calibre12">x</i> = <i class="calibre12">a</i><sup class="calibre19"><i class="calibre22">φ</i>(<i class="calibre22">n</i>)-1</sup> mod <i class="calibre12">n</i>
</p>

<p class="calibre9">For example, what is the inverse of 5, modulo 7? Since 7 is prime, φ(7) = 7 - 1 = 6. So, the inverse of 5, modulo 7, is</p>

<p class="math">5<sup class="calibre19">6-1</sup> mod 7 = 5<sup class="calibre19">5</sup> mod 7 = 3
</p>

<p class="calibre9">Both methods for calculating inverses can be extended to solve for <i class="calibre12">x</i> in the general problem (if gcd(<i class="calibre12">a,n</i>) = 1):</p>

<p class="math">(<i class="calibre12">a*x</i>) mod <i class="calibre12">n</i> = <i class="calibre12">b</i>
</p>

<p class="calibre9">Using Euler’s generalization, solve</p>

<p class="math"><i class="calibre12">x</i> = (<i class="calibre12">b*a</i><sup class="calibre19">φ(<i class="calibre22">n</i>)-1</sup>) mod <i class="calibre12">n</i>
</p>

<p class="calibre9">Using Euclid’s algorithm, solve</p>

<p class="math"><i class="calibre12">x</i> = (<i class="calibre12">b</i>*(<i class="calibre12">a</i><sup class="calibre19">-1</sup> mod <i class="calibre12">n</i>)) mod <i class="calibre12">n</i>
</p>

<p class="calibre9">In general, Euclid’s algorithm is faster than Euler’s generalization for calculating inverses, especially for numbers in the 500-bit range. If gcd(<i class="calibre12">a,n</i>) ≠ 1, all is not lost. In this general case, (<i class="calibre12">a*x</i>) mod <i class="calibre12">n</i> = <i class="calibre12">b</i>, can have multiple solutions or no solution.</p>

<h4 class="calibre8">Chinese Remainder Theorem</h4>

<p class="calibre9">If you know the prime factorization of <i class="calibre12">n</i>, then you can use something called the <b class="calibre10">Chinese</b> <b class="calibre10">remainder theorem</b> to solve a whole system of equations. The basic version of this theorem was discovered by the first-century Chinese mathematician, Sun Tse.</p>

<p class="calibre9">In general, if the prime factorization of <i class="calibre12">n</i> is <i class="calibre12">p</i><sub class="calibre15">1</sub> * <i class="calibre12">p</i><sub class="calibre15">2</sub> * ... * <i class="calibre12">p</i><sub class="calibre15">i</sub>, then the system of equations</p>

<p class="math">(<i class="calibre12">x</i> mod <i class="calibre12">p<sub class="calibre15">i</sub></i>) = <i class="calibre12">a<sub class="calibre15">i</sub></i>, where <i class="calibre12">i</i> = 1, 2 <i class="calibre12">, ... </i>, <i class="calibre12">t</i>
</p>

<p class="calibre9">has a unique solution, <i class="calibre12">x</i>, where <i class="calibre12">x</i> is less than <i class="calibre12">n. </i> (Note that some primes can appear more than once. For example, <i class="calibre12">p</i><sub class="calibre15">1</sub> might be equal to <i class="calibre12">p</i><sub class="calibre15">2</sub>.) In other words, a number (less than the product of some primes) is uniquely identified by its residues mod those primes.</p>

<p class="calibre9">For example, use 3 and 5 as primes, and 14 as the number. 14 mod 3 = 2, and 14 mod 5 =
4. There is only one number less than 3*5 = 15 which has those residues: 14. The two
residues uniquely determine the number.</p>

<p class="calibre9">So, for an arbitrary <i class="calibre12">a</i> &lt; <i class="calibre12">p</i> and <i class="calibre12">b</i> &lt; <i class="calibre12">q</i> (where <i class="calibre12">p</i> and <i class="calibre12">q</i> are prime), there exists a unique <i class="calibre12">x</i>, where <i class="calibre12">x</i> is less than <i class="calibre12">pq</i>, such that</p>

<p class="math"><i class="calibre12">x</i> ≡ a (mod <i class="calibre12">p</i>), and <i class="calibre12">x</i> ≡ <i class="calibre12">b</i> (mod <i class="calibre12">q</i>)
</p>

<p class="calibre9">To find this <i class="calibre12">x</i>, first use Euclid’s algorithm to find <i class="calibre12">u</i>, such that</p>

<p class="math"><i class="calibre12">u*q</i> ≡ 1 (mod <i class="calibre12">p</i>)
</p>

<p class="calibre9">Then compute:</p>

<p class="math"><i class="calibre12">x</i> = (((<i class="calibre12">a</i> - <i class="calibre12">b</i>)*<i class="calibre12">u</i>) mod <i class="calibre12">p</i>)*<i class="calibre12">q</i> + <i class="calibre12">b</i>
</p>

<p class="calibre9">Here is the Chinese remainder theorem in C:</p>

<pre class="calibre20">/* r is the number of elements in arrays m and u;
m is the array of (pairwise relatively prime) moduli
u is the array of coefficients
return value is n such than n == u[k]%m[k] (k=0..r-1) and
    n &lt; m[0]*m[1]*...*m[r-1]
*/

/* totient() is left as an exercise to the reader. */
int chinese_remainder (size_t r, int *m, int *u)
{
    size_t i;
    int modulus;
    int n;
    modulus = 1;

    for (i=0; i&lt;r; ++i)
        modulus *= m[i];
    n = 0;
    for (i=0; i&lt;r; ++i) {
        n += u[i] * modexp(modulus / m[i], totient(m[i]),
        m[i]);
        n %= modulus;
    }

    return n;
}
</pre>

<p class="calibre9">The converse of the Chinese remainder theorem can also be used to find the solution to the problem: if <i class="calibre12">p</i> and <i class="calibre12">q</i> are primes, and <i class="calibre12">p</i> is less than <i class="calibre12">q</i>, then there exists a unique <i class="calibre12">x</i> less than <i class="calibre12">pq</i>, such that</p>

<p class="math"><i class="calibre12">a</i> ≡ x (mod <i class="calibre12">p</i>), and <i class="calibre12">b</i> ≡ x (mod <i class="calibre12">q</i>)
</p>

<p class="calibre9">If <i class="calibre12">a</i> e <i class="calibre12">b</i> mod <i class="calibre12">p</i>, then</p>

<p class="math"><i class="calibre12">x</i> = (((<i class="calibre12">a</i> - (<i class="calibre12">b</i> mod <i class="calibre12">p</i>)) * <i class="calibre12">u</i>) mod <i class="calibre12">p</i>) * <i class="calibre12">q + b</i>
</p>

<p class="calibre9">If <i class="calibre12">a</i> &lt; <i class="calibre12">b</i> mod <i class="calibre12">p</i>, then</p>

<p class="math"><i class="calibre12">x</i> = (((<i class="calibre12">a</i> + p - (<i class="calibre12">b</i> mod <i class="calibre12">p</i>)) * <i class="calibre12">u</i>) mod <i class="calibre12">p</i>) * <i class="calibre12">q + b</i>
</p>

<h4 class="calibre8">Quadratic Residues</h4>

<p class="calibre9">If <i class="calibre12">p</i> is prime, and <i class="calibre12">a</i> is greater than 0 and less than <i class="calibre12">p</i>, then <i class="calibre12">a</i> is a <b class="calibre10">quadratic residue</b> mod <i class="calibre12">p</i> if</p>

<p class="math"><i class="calibre12">x</i><sup class="calibre19">2</sup> ≡ a (mod <i class="calibre12">p</i>), for some <i class="calibre12">x</i>
</p>

<p class="calibre9">Not all values of <i class="calibre12">a</i> satisfy this property. For <i class="calibre12">a</i> to be a quadratic residue modulo <i class="calibre12">n</i>, it must be a quadratic residue modulo all the prime factors of <i class="calibre12">n. </i> For example, if <i class="calibre12">p</i> = 7, the quadratic residues are 1, 2, and 4:</p>

<p class="math">1<sup class="calibre19">2</sup> = 1 ≡ 1 (mod 7)
2<sup class="calibre19">2</sup> = 4 ≡ 4 (mod 7)
3<sup class="calibre19">2</sup> = 9 ≡ 2 (mod 7)
4<sup class="calibre19">2</sup> = 16 ≡ 2 (mod 7)
5<sup class="calibre19">2</sup> = 25 ≡ 4 (mod 7)
6<sup class="calibre19">2</sup> = 36 ≡ 1 (mod 7)
</p>

<p class="calibre9">Note that each quadratic residue appears twice on this list.</p>

<p class="calibre9">There are no values of <i class="calibre12">x</i> which satisfy any of these equations:</p>

<p class="math"><i class="calibre12">x<sup class="calibre19">2</sup></i> ≡ 3 (mod 7)
<i class="calibre12">x<sup class="calibre19">2</sup></i> ≡ 5 (mod 7)
<i class="calibre12">x<sup class="calibre19">2</sup></i> ≡ 6 (mod 7)
</p>

<p class="calibre9">The <b class="calibre10">quadratic nonresidues</b> modulo 7, the numbers that are not quadratic residues, are 3, 5, and 6.</p>

<p class="calibre9">Although I will not do so here, it is easy to prove that, when <i class="calibre12">p</i> is odd, there are exactly (<i class="calibre12">p</i> - 1)/2 quadratic 
residues mod <i class="calibre12">p</i> and the same number of quadratic nonresidues mod <i class="calibre12">p. </i><sub class="calibre15">A</sub>lso, if <i class="calibre12">a</i> is a quadratic residue mod <i class="calibre12">p</i>, then <i class="calibre12">a</i> has exactly two square roots, one of them between 0 and (<i class="calibre12">p</i> - 1)/2, and the other between (<i class="calibre12">p</i> - 1)/2 and (<i class="calibre12">p</i> - 1). One of these square roots is also a quadratic residue mod <i class="calibre12">p; </i> this is called the <b class="calibre10">principal square root</b>.</p>

<p class="calibre9">If <i class="calibre12">n</i> is the product of two primes, <i class="calibre12">p</i> and <i class="calibre12">q</i>, there are exactly (<i class="calibre12">p</i> - 1)(<i class="calibre12">q</i> - 1)/4 quadratic residues mod <i class="calibre12">n</i>. A quadratic residue mod <i class="calibre12">n</i> is a perfect square modulo <i class="calibre12">n.</i> This is because to be a square mod <i class="calibre12">n</i>, the residue must be a square mod <i class="calibre12">p</i> and a square mod <i class="calibre12">q. </i> For example, there are 11 quadratic residues mod 35: 1, 4, 9, 11, 14, 15, 16, 21, 25, 29, and 30. Each quadratic residue has exactly four square roots.</p>

<h4 class="calibre8">Legendre Symbol</h4>

<p class="calibre9">The <b class="calibre10">Legendre symbol</b>, written <i class="calibre12">L</i>(<i class="calibre12">a,p</i>), is defined when <i class="calibre12">a</i> is any integer and <i class="calibre12">p</i> is a prime greater than 2. It is equal to 0, 1, or -1.</p>

<p class="math"><i class="calibre12">L</i>(<i class="calibre12">a,p</i>) = 0 if <i class="calibre12">a</i> is divisible by <i class="calibre12">p. </i>
<i class="calibre12">L</i>(<i class="calibre12">a,p</i>) = 1 if <i class="calibre12">a</i> is a quadratic residue mod <i class="calibre12">p</i>.
<i class="calibre12">L</i>(<i class="calibre12">a,p</i>) = - 1 is <i class="calibre12">a</i> is a quadratic nonresidue mod <i class="calibre12">p</i>.
</p>

<p class="calibre9">One way to calculate <i class="calibre12">L</i>(<i class="calibre12">a,p</i>) is:</p>

<p class="math"><i class="calibre12">L</i>(<i class="calibre12">a,p</i>) = <i class="calibre12">a</i><sup class="calibre19">(<i class="calibre22">p</i>-1)/2</sup> mod <i class="calibre12">p</i>
</p>

<p class="calibre9">Or you can use the following algorithm:</p>

<ol class="calibre17">

<li class="calibre14">If <i class="calibre12">a</i> = 1, then <i class="calibre12">L</i>(<i class="calibre12">a,p</i>) = 1
</li>
<li class="calibre14">If <i class="calibre12">a</i> is even, then <i class="calibre12">L</i>(<i class="calibre12">a,p</i>) = <i class="calibre12">L</i>(<i class="calibre12">a</i>/2, <i class="calibre12">p</i>)*(-1)<sup class="calibre19">(<i class="calibre22">p</i><sup class="calibre66">2</sup>-1)/8</sup>
</li>
<li class="calibre14">If <i class="calibre12">a</i> is odd (and ≠ 1), then <i class="calibre12">L</i>(<i class="calibre12">a,p</i>) = <i class="calibre12">L</i>(<i class="calibre12">p</i> mod <i class="calibre12">a,a</i>)*(-1)<sup class="calibre19">(<i class="calibre22">a</i>-1)*(<i class="calibre22">p</i>-1)/4</sup>
</li>

</ol>

<p class="calibre9">Note that this is also an efficient way to determine whether <i class="calibre12">a</i> is a quadratic residue mod <i class="calibre12">p</i> (when <i class="calibre12">p</i> is prime).</p>

<h4 class="calibre8">Jacobi Symbol</h4>

<p class="calibre9">The <b class="calibre10">Jacobi symbol</b>, written <i class="calibre12">J</i>(<i class="calibre12">a,n</i>), is a generalization of the Legendre symbol to composite moduli; it is defined for any integer <i class="calibre12">a</i> and any odd integer <i class="calibre12">n.</i> The function shows up in primality testing. The Jacobi symbol is a function on the set of reduced residues of the divisors of <i class="calibre12">n</i> and can be calculated by several formulas [<a href="Applied%20Cryptography_split_036.html#r1412" class="calibre5 pcalibre">1412</a>]. This is one method:</p>

<ul class="split1">
<li class="calibre35">Definition 1: <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) is only defined if <i class="calibre12">n</i> is odd.</li>
<li class="calibre35">Definition 2: <i class="calibre12">J</i>(0,<i class="calibre12">n</i>) = 0.</li>
<li class="calibre35">Definition 3: If <i class="calibre12">n</i> is prime, then the Jacobi symbol <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) = 0 if <i class="calibre12">n</i> divides <i class="calibre12">a</i>.</li>
<li class="calibre35">Definition 4: If <i class="calibre12">n</i> is prime, then the Jacobi symbol <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) = 1 if <i class="calibre12">a</i> is a quadratic residue modulo <i class="calibre12">n. </i></li>
<li class="calibre35">Definition 5: If <i class="calibre12">n</i> is prime, then the Jacobi symbol <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) = -1 if <i class="calibre12">a</i> is a quadratic nonresidue modulo <i class="calibre12">n</i>.</li>
<li class="calibre35">Definition 6: If <i class="calibre12">n</i> is composite, then the Jacobi symbol <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) = <i class="calibre12">J</i>(<i class="calibre12">a,p</i><sub class="calibre15">1</sub>) * ... * <i class="calibre12">J</i>(<i class="calibre12">a,p<sub class="calibre15">m</sub></i>), where 
<i class="calibre12">p</i><sub class="calibre15">1</sub> ...  <i class="calibre12">p<sub class="calibre15">m</sub></i> is the prime factorization of <i class="calibre12">n</i>.</li>
</ul>

<p class="calibre9">The following algorithm computes the Jacobi symbol recursively:</p>

<ul class="split1">
<li class="calibre35">Rule 1: <i class="calibre12">J</i>(1, <i class="calibre12">n</i>) = 1</li>
<li class="calibre35">Rule 2: <i class="calibre12">J</i>(<i class="calibre12">a*b,n</i>) = <i class="calibre12">J</i>(<i class="calibre12">a,n</i>)*<i class="calibre12">J</i>(<i class="calibre12">b,n</i>)</li>
<li class="calibre35">Rule 3: <i class="calibre12">J</i>(2, <i class="calibre12">n</i>) = 1 if (<i class="calibre12">n</i><sup class="calibre19">2</sup> - 1)/8 is even, and - 1 otherwise</li>
<li class="calibre35">Rule 4: <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) = <i class="calibre12">J</i>((<i class="calibre12">a</i> mod <i class="calibre12">n</i>), <i class="calibre12">n</i>)</li>
<li class="calibre35">Rule 5: <i class="calibre12">J</i>(<i class="calibre12">a,b</i><sub class="calibre15">1</sub>* <i class="calibre12">b</i><sub class="calibre15">2</sub>) = <i class="calibre12">J</i>(<i class="calibre12">a,b</i><sub class="calibre15">1</sub>)*<i class="calibre12">J</i>(<i class="calibre12">a,b</i><sub class="calibre15">2</sub>)</li>
<li class="calibre35">Rule 6: If the greatest common divisor of <i class="calibre12">a</i> and <i class="calibre12">b</i> = 1, and <i class="calibre12">a</i> and <i class="calibre12">b</i> are odd:</li>
<li class="calibre35">Rule 6a: <i class="calibre12">J</i>(<i class="calibre12">a,b</i>) = <i class="calibre12">J</i>(<i class="calibre12">b,a</i>) if (<i class="calibre12">a</i> - 1)(<i class="calibre12">b</i> - 1)/4 is even</li>
<li class="calibre35">Rule 6b: <i class="calibre12">J</i>(<i class="calibre12">a,b</i>) = -<i class="calibre12">J</i>(<i class="calibre12">b,a</i>) if (<i class="calibre12">a</i> - 1)(<i class="calibre12">b</i> - 1)/4 is odd</li>
</ul>

<p class="calibre9">Here is the algorithm in C:</p>

<pre class="calibre20">/* This algorithm computes the Jacobi symbol recursively */
int jacobi(int a, int b)
{
    int g;

    assert(odd(b));

    if (a &gt;= b) a %= b;         /* by Rule 4 */
    if (a == 0) return 0;       /* by Definition 2 */
    if (a == 1) return 1;       /* by Rule 1 */

    if (a &lt; 0)
        if (((b-1)/2 % 2 == 0)
            return jacobi(-a,b);
        else
            return -jacobi(-a,b);

    if (a % 2 == 0) /* a is even */
        if (((b*b - 1)/8) % 2 == 0)
            return +jacobi(a/2, b)
        else
            return -jacobi(a/2, b) /* by Rule 3 and Rule 2 */

    g = gcd(a,b);

    assert(odd(a)); /* this is guaranteed by the (a % 2 == 0) test */

    if (g == a) /* a exactly divides b */
        return 0; /* by Rules 5 and 4, and Definition 2 */
    else if (g != 1)
        return jacobi(g,b) * jacobi(a/g, b); /* by Rule 2 */
    else if (((a-1)*(b-1)/4) % 2 == 0)
        return +jacobi(b,a);    /* by Rule 6a */
    else
        return -jacobi(b,a);    /* by Rule 6b */
}
</pre>

<p class="calibre9">If <i class="calibre12">n</i> is known to be prime beforehand, simply compute <i class="calibre12">a</i><sup class="calibre19">((<i class="calibre22">n</i>-1)/2)</sup> mod <i class="calibre12">n</i> instead of running the previous algorithm; in this case <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) is equivalent to the Legendre symbol.</p>

<p class="calibre9">The Jacobi symbol cannot be used to determine whether <i class="calibre12">a</i> is a quadratic residue mod <i class="calibre12">n</i> (unless <i class="calibre12">n</i> is prime, of course). Note that, if <i class="calibre12">J</i>(<i class="calibre12">a,n</i>) = 1 and <i class="calibre12">n</i> is composite, it is not necessarily true that <i class="calibre12">a</i> is a quadratic residue modulo <i class="calibre12">n</i>. For example:</p>

<p class="math"><i class="calibre12">J</i>(7, 143) = <i class="calibre12">J</i>(7, 11)*<i class="calibre12">J</i>(7, 13) = (-1)(-1) = 1
</p>

<p class="calibre9">However, there is no integer <i class="calibre12">x</i> such that <i class="calibre12">x</i><sup class="calibre19">2</sup> ≡ 7 (mod 143).</p>

<h4 class="calibre8">Blum Integers</h4>

<p class="calibre9">If <i class="calibre12">p</i> and <i class="calibre12">q</i> are two primes, and both are congruent to 3 modulo 4, then <i class="calibre12">n</i> = <i class="calibre12">pq</i> is sometimes called a <b class="calibre10">Blum integer</b>. If <i class="calibre12">n</i> is a Blum integer, each quadratic residue has exactly four square roots, one of which is also a square; this is the principal square root. For example, the principal square root of 139 mod 437 is 24. The other three square roots are 185, 252, and 413.</p>

<h4 class="calibre8">Generators</h4>

<p class="calibre9">If <i class="calibre12">p</i> is a prime, and <i class="calibre12">g</i> is less than <i class="calibre12">p</i>, then <i class="calibre12">g</i> is a <b class="calibre10">generator</b> mod <i class="calibre12">p</i> if</p>

<p class="math">for each <i class="calibre12">b</i> from 1 to <i class="calibre12">p</i> - 1, there exists some <i class="calibre12">a</i> where <i class="calibre12">g<sup class="calibre19">a</sup></i> ≡ b (mod <i class="calibre12">p</i>).
</p>

<p class="calibre9">Another way of saying this is that <i class="calibre12">g</i> is <b class="calibre10">primitive</b> with respect to <i class="calibre12">p</i>.</p>

<p class="calibre9">For example, if <i class="calibre12">p</i> = 11, 2 is a generator mod 11:</p>

<p class="math">2<sup class="calibre19">10</sup> = 1024 ≡ 1 (mod 11)
2<sup class="calibre19">1</sup> = 2 ≡ 2 (mod 11)
2<sup class="calibre19">8</sup> = 256 ≡ 3 (mod 11)
2<sup class="calibre19">2</sup> = 4 ≡ 4 (mod 11)
2<sup class="calibre19">4</sup> = 16 ≡ 5 (mod 11)
2<sup class="calibre19">9</sup> = 512 ≡ 6 (mod 11)
2<sup class="calibre19">7</sup> = 128 ≡ 7 (mod 11)
2<sup class="calibre19">3</sup> = 8 ≡ 8 (mod 11)
2<sup class="calibre19">6</sup> = 64 ≡ 9 (mod 11)
2<sup class="calibre19">5</sup> = 32 ≡ 10 (mod 11)
</p>

<p class="calibre9">Every number from 1 to 10 can be expressed as 2<sup class="calibre19"><i class="calibre22">a</i></sup> (mod <i class="calibre12">p</i>).</p>

<p class="calibre9">For <i class="calibre12">p</i> = 11, the generators are 2, 6, 7, and 8. The other numbers are not generators. For example, 3 is not a generator because there is no solution to</p>

<p class="math">3<sup class="calibre19"><i class="calibre22">a</i></sup> = 2 (mod 11)
</p>

<p class="calibre9">In general, testing whether a given number is a generator is not an easy problem. It is easy, however, if you know the factorization of <i class="calibre12">p</i> - 1. Let <i class="calibre12">q</i><sub class="calibre15">1</sub>, <i class="calibre12">q</i><sub class="calibre15">2</sub>, ... , <i class="calibre12">q</i><sub class="calibre15">m</sub> be the distinct prime factors of <i class="calibre12">p</i> - 1. To test whether a number <i class="calibre12">g</i> is a generator mod <i class="calibre12">p</i>, calculate</p>

<p class="math"><i class="calibre12">g</i><sup class="calibre19">(<i class="calibre22">p-</i>1)/<i class="calibre22">q</i></sup> mod <i class="calibre12">p</i>
</p>

<p class="calibre9">for all values of <i class="calibre12">q</i> = <i class="calibre12">q</i><sub class="calibre15">1</sub>, <i class="calibre12">q</i><sub class="calibre15">2</sub>, ... , <i class="calibre12">q</i><sub class="calibre15"><i class="calibre22">m</i></sub>.</p>

<p class="calibre9">If that number equals 1 for some value of <i class="calibre12">q</i>, then <i class="calibre12">g</i> is not a generator. If that value does not equal 1 for any values of <i class="calibre12">q</i>, then <i class="calibre12">g</i> is a generator.</p>

<p class="calibre9">For example, let <i class="calibre12">p</i> = 11. The prime factors of <i class="calibre12">p</i> - 1 = 10 are 2 and 5. To test whether 2 is a generator:</p>

<p class="math">2<sup class="calibre19">(11-1)/5</sup> (mod 11) = 4
2<sup class="calibre19">(11-1)/2</sup> (mod 11) = 10
</p>

<p class="calibre9">Neither result is 1, so 2 is a generator.</p>

<p class="calibre9">To test whether 3 is a generator:</p>

<p class="math">3<sup class="calibre19">(11-1)/5</sup> (mod 11) = 9
3<sup class="calibre19">(11-1)/2</sup> (mod 11) = 1
</p>

<p class="calibre9">Therefore, 3 is not a generator.</p>

<p class="calibre9">If you need to find a generator mod <i class="calibre12">p</i>, simply choose a random number from 1
to <i class="calibre12">p</i> - 1 and test whether it is a generator. Enough of them will be, so you’ll probably find one fast.</p>

<h4 class="calibre8">Computing in a Galois Field</h4>

<p class="calibre9">Don’t be alarmed; that’s what we were just doing. If <i class="calibre12">n</i> is prime or the power of a large prime, then we have what mathematicians call a <b class="calibre10">finite field</b>. In honor
of that fact, we use <i class="calibre12">p</i> instead of <i class="calibre12">n. </i> In fact, this type of finite field is so exciting that mathematicians gave it its own name: a <b class="calibre10">Galois field</b>, denoted as GF(<i class="calibre12">p</i>).
(Évariste Galois was a French mathematician who lived in the early nineteenth
century and did a lot of work in number theory before he was killed at age 20
in a duel.)</p>

<p class="calibre9">In a Galois field, addition, subtraction, multiplication, and division by nonzero
elements are all well-defined. There is an additive identity, 0, and a
multiplicative identity, 1. Every nonzero number has a unique inverse (this
would not be true if <i class="calibre12">p</i> were not prime). The commutative, associative, and
distributive laws are true.</p>

<p class="calibre9">Arithmetic in a Galois field is used a great deal in cryptography. All of the
number theory works; it keeps numbers a finite size, and division doesn’t have
any rounding errors. Many cryptosystems are based on GF(<i class="calibre12">p</i>), where <i class="calibre12">p</i> is a large prime.</p>

<p class="calibre9">To make matters even more complicated, cryptographers also use arithmetic
modulo <b class="calibre10">irreducible</b> polynomials of degree <i class="calibre12">n</i> whose coefficients are integers modulo <i class="calibre12">q</i>, where <i class="calibre12">q</i> is prime. These fields are called GF(<i class="calibre12">q<sup class="calibre19">n</sup></i>). All arithmetic is done modulo <i class="calibre12">p</i> (<i class="calibre12">x</i>), where <i class="calibre12">p</i> (<i class="calibre12">x</i>) is an irreducible polynomial of degree <i class="calibre12">n. </i></p>

<p class="calibre9">The mathematical theory behind this is far beyond the scope of the book,
although I will describe some cryptosystems that use it. If you want to try to
work more with this, GF(2<sup class="calibre19">3</sup>) has the following elements: 0, 1, <i class="calibre12">x, x</i> + 1, <i class="calibre12">x</i><sup class="calibre19">2</sup>, <i class="calibre12">x</i><sup class="calibre19">2</sup> +
1, <i class="calibre12">x</i><sup class="calibre19">2</sup> + <i class="calibre12">x, x</i><sup class="calibre19">2</sup> + <i class="calibre12">x</i> + 1. There is an algorithm for computing inverses in GF(2<sup class="calibre19">n</sup>) that is suitable for parallel implementation [<a href="Applied%20Cryptography_split_035.html#r421" class="calibre5 pcalibre">421</a>].</p>

<p class="calibre9">When talking about polynomials, the term “prime” is replaced by
“irreducible.” A polynomial is irreducible if it cannot be expressed as the
product of two other polynomials (except for 1 and itself, of course). The
polynomial <i class="calibre12">x</i><sup class="calibre19">2</sup> + 1 is irreducible over the integers. 
The polynomial <i class="calibre12">x</i><sup class="calibre19">3</sup> + 2<i class="calibre12">x</i><sup class="calibre19">2</sup> + <i class="calibre12">x</i> is not; it can be expressed as <i class="calibre12">x</i>(<i class="calibre12">x</i> + 1)(<i class="calibre12">x</i> + 1).</p>

<p class="calibre9">A polynomial that is a generator in a given field is called primitive; all its
coefficients are relatively prime. We’ll see primitive polynomials again when
we talk about linear-feedback shift registers (see <a href="Applied%20Cryptography_split_019.html#16.2" class="calibre5 pcalibre">Section 16.2</a>).</p>

<p class="calibre9">Computation in GF(2<sup class="calibre19"><i class="calibre22">n</i></sup>) can be quickly implemented in hardware with
linear-feedback shift registers. For that reason, computation over GF(2<sup class="calibre19"><i class="calibre22">n</i></sup>) is
often quicker than computation over GF(<i class="calibre12">p</i>). Just as exponentiation is much
more efficient in GF(2<sup class="calibre19"><i class="calibre22">n</i></sup>), so is calculating discrete logarithms [<a href="Applied%20Cryptography_split_035.html#r180" class="calibre5 pcalibre">180</a>,<a href="Applied%20Cryptography_split_035.html#r181" class="calibre5 pcalibre">181</a>,<a href="Applied%20Cryptography_split_035.html#r368" class="calibre5 pcalibre">368</a>,<a href="Applied%20Cryptography_split_035.html#r379" class="calibre5 pcalibre">379</a>]. If you want to learn more about this, read [<a href="Applied%20Cryptography_split_035.html#r140" class="calibre5 pcalibre">140</a>].</p>

<p class="calibre9">For a Galois field GF(2<sup class="calibre19"><i class="calibre22">n</i></sup>), cryptographers like to use the trinomial <i class="calibre12">p</i> (<i class="calibre12">x</i>) = <i class="calibre12">x<sup class="calibre19">n</sup></i> + <i class="calibre12">x</i> + 1 
as the modulus, because the long string of zeros between the <i class="calibre12">x<sup class="calibre19">n</sup></i> and <i class="calibre12">x</i> coefficients makes it easy to implement a fast modular multiplication [<a href="Applied%20Cryptography_split_035.html#r183" class="calibre5 pcalibre">183</a>].
The trinomial must be primitive, otherwise the math does not work. Values of
 <i class="calibre12">n</i> less than 1000 [<a href="Applied%20Cryptography_split_036.html#r1649" class="calibre5 pcalibre">1649</a>,<a href="Applied%20Cryptography_split_036.html#r1648" class="calibre5 pcalibre">1648</a>] for which <i class="calibre12">x<sup class="calibre19">n</sup></i> + <i class="calibre12">x</i> + 1 is primitive are:</p>

<pre class="calibre20">1, 3, 4, 6, 9, 15, 22, 28, 30, 46, 60, 63, 127, 153, 172, 303, 471, 532, 865, 900.
</pre>

<p class="calibre9">There exists a hardware implementation of GF(2<sup class="calibre19">127</sup>) where <i class="calibre12">p</i>(<i class="calibre12">x</i>) = <i class="calibre12">x</i><sup class="calibre19">127</sup> + <i class="calibre12">x</i> + 1
[<a href="Applied%20Cryptography_split_036.html#r1631" class="calibre5 pcalibre">1631</a>, <a href="Applied%20Cryptography_split_036.html#r1632" class="calibre5 pcalibre">1632</a>, <a href="Applied%20Cryptography_split_036.html#r1129" class="calibre5 pcalibre">1129</a>]. Efficient hardware architectures for implementing
exponentiation in GF(2<sup class="calibre19"><i class="calibre22">n</i></sup>) are discussed in [<a href="Applied%20Cryptography_split_035.html#r147" class="calibre5 pcalibre">147</a>].</p>

<h3 id="11.4" class="calibre7">11.4 Factoring</h3>

<p class="calibre9">Factoring a number means finding its prime factors.</p>

<p class="math">10 = 2*5
60 = 2*2*3*5
252601 = 41*61*101
2<sup class="calibre19">113</sup> - 1 = 3391*23279*65993*1868569*1066818132868207
</p>

<p class="calibre9">The factoring problem is one of the oldest in number theory. It’s simple to
factor a number, but it’s time-consuming. This is still true, but there have been
some major advances in the state of the art.</p>

<p class="calibre9">Currently, the best factoring algorithm is:</p>

<p class="quote"><b class="calibre10">Number field sieve (NFS)</b> [<a href="Applied%20Cryptography_split_036.html#r953" class="calibre5 pcalibre">953</a>] (see also [<a href="Applied%20Cryptography_split_036.html#r952" class="calibre5 pcalibre">952</a>,<a href="Applied%20Cryptography_split_035.html#r16" class="calibre5 pcalibre">16</a>,<a href="Applied%20Cryptography_split_035.html#r279" class="calibre5 pcalibre">279</a>]). The <b class="calibre10">general</b>
<b class="calibre10">number field sieve</b> is the fastest-known factoring algorithm for
numbers larger than 110 digits or so [<a href="Applied%20Cryptography_split_035.html#r472" class="calibre5 pcalibre">472</a>,<a href="Applied%20Cryptography_split_035.html#r635" class="calibre5 pcalibre">635</a>]. It was impractical when
originally proposed, but that has changed due to a series of
improvements over the last few years [<a href="Applied%20Cryptography_split_036.html#r953" class="calibre5 pcalibre">953</a>]. The NFS is still too new to
have broken any factoring records, but this will change soon. An early
version was used to factor the ninth Fermat number: 2<sup class="calibre19">512</sup> + 1 [<a href="Applied%20Cryptography_split_036.html#r955" class="calibre5 pcalibre">955</a>,<a href="Applied%20Cryptography_split_036.html#r954" class="calibre5 pcalibre">954</a>].</p>

<p class="calibre9">Other factoring algorithms have been supplanted by the NFS:</p>

<p class="quote"><b class="calibre10">Quadratic sieve (QS)</b> [<a href="Applied%20Cryptography_split_036.html#r1257" class="calibre5 pcalibre">1257</a>,<a href="Applied%20Cryptography_split_036.html#r1617" class="calibre5 pcalibre">1617</a>,<a href="Applied%20Cryptography_split_036.html#r1259" class="calibre5 pcalibre">1259</a>]. This is the fastest-known
algorithm for numbers less than 110 decimal digits long and has been
used extensively [<a href="Applied%20Cryptography_split_035.html#r440" class="calibre5 pcalibre">440</a>]. A faster version of this algorithm is called the
multiple polynomial quadratic sieve [<a href="Applied%20Cryptography_split_036.html#r1453" class="calibre5 pcalibre">1453</a>,<a href="Applied%20Cryptography_split_035.html#r302" class="calibre5 pcalibre">302</a>]. The fastest version of
this algorithm is called the double large prime variation of the multiple
polynomial quadratic sieve. <br class="calibre3"/>
<b class="calibre10">Elliptic curve method (ECM)</b> [<a href="Applied%20Cryptography_split_036.html#r957" class="calibre5 pcalibre">957</a>,<a href="Applied%20Cryptography_split_036.html#r1112" class="calibre5 pcalibre">1112</a>,<a href="Applied%20Cryptography_split_036.html#r1113" class="calibre5 pcalibre">1113</a>]. This method has been
used to find 43-digit factors, but nothing larger. <br class="calibre3"/>
<b class="calibre10">Pollard’s Monte Carlo algorithm</b> [<a href="Applied%20Cryptography_split_036.html#r1254" class="calibre5 pcalibre">1254</a>,<a href="Applied%20Cryptography_split_035.html#r248" class="calibre5 pcalibre">248</a>]. (This algorithm also
appears in volume 2, page 370 of Knuth [<a href="Applied%20Cryptography_split_036.html#r863" class="calibre5 pcalibre">863</a>].) <br class="calibre3"/>
<b class="calibre10">Continued fraction algorithm. </b> See [<a href="Applied%20Cryptography_split_036.html#r1123" class="calibre5 pcalibre">1123</a>,<a href="Applied%20Cryptography_split_036.html#r1252" class="calibre5 pcalibre">1252</a>,<a href="Applied%20Cryptography_split_036.html#r863" class="calibre5 pcalibre">863</a>]. This algorithm
isn’t even in the running. <br class="calibre3"/>
<b class="calibre10">Trial division. </b> This is the oldest factoring algorithm and consists of
testing every prime number less than or equal to the square root of the
candidate number.</p>

<p class="calibre9">See [<a href="Applied%20Cryptography_split_035.html#r251" class="calibre5 pcalibre">251</a>] for a good introduction to these different factoring algorithms,
except for the NFS. The best discussion of the NFS is [<a href="Applied%20Cryptography_split_036.html#r953" class="calibre5 pcalibre">953</a>]. Other, older
references are [<a href="Applied%20Cryptography_split_035.html#r505" class="calibre5 pcalibre">505</a>,<a href="Applied%20Cryptography_split_036.html#r1602" class="calibre5 pcalibre">1602</a>,<a href="Applied%20Cryptography_split_036.html#r1258" class="calibre5 pcalibre">1258</a>]. Information on parallel factoring can be
found in [<a href="Applied%20Cryptography_split_035.html#r250" class="calibre5 pcalibre">250</a>].</p>

<p class="calibre9">If <i class="calibre12">n</i> is the number being factored, the fastest QS variants have a heuristic
asymptotic run time of:</p>

<p class="math">e<sup class="calibre19">(1 + 0(1))(ln(<i class="calibre22">n</i>))<sup class="calibre66">(1/2)</sup>(ln(ln(<i class="calibre22">n</i>)))<sup class="calibre66">(1/2)</sup></sup>
</p>

<p class="calibre9">The NFS is much faster, with a heuristic asymptotic time estimate of:</p>

<p class="math">e<sup class="calibre19">(1.923+ 0(1))(ln(<i class="calibre22">n</i>))<sup class="calibre66">(1/3)</sup>(ln(ln(<i class="calibre22">n</i>)))<sup class="calibre66">(2/3)</sup></sup>
</p>

<p class="calibre9">In 1970, the big news was the factoring of a 41-digit hard number [<a href="Applied%20Cryptography_split_036.html#r1123" class="calibre5 pcalibre">1123</a>]. (A
“hard” number is one that does not have any small factors and is not of a
special form that allows it to be factored more easily.) Ten years later,
factoring hard numbers twice that size took a Cray computer just a few hours
[<a href="Applied%20Cryptography_split_035.html#r440" class="calibre5 pcalibre">440</a>].</p>

<p class="calibre9">In 1988, Carl Pomerance designed a modular factoring machine, using custom
VLSI chips [<a href="Applied%20Cryptography_split_036.html#r1259" class="calibre5 pcalibre">1259</a>]. The size of the number you would be able to factor
depends on how large a machine you can afford to build. He never built it.</p>

<p class="calibre9">In 1993, a 120-digit hard number was factored using the quadratic sieve; the
calculation took 825 mips-years and was completed in three months real time
[<a href="Applied%20Cryptography_split_035.html#r463" class="calibre5 pcalibre">463</a>]. Other results are [<a href="Applied%20Cryptography_split_035.html#r504" class="calibre5 pcalibre">504</a>].</p>

<p class="calibre9">Today’s factoring attempts use computer networks [<a href="Applied%20Cryptography_split_035.html#r302" class="calibre5 pcalibre">302</a>,<a href="Applied%20Cryptography_split_036.html#r955" class="calibre5 pcalibre">955</a>]. In factoring a
116-digit number, Arjen Lenstra and Mark Manasse used 400 mips-years — the
spare time on an array of computers around the world for a few months.</p>

<p class="calibre9">In March 1994, a 129-digit (428-bit) number was factored using the double
large prime variation of the multiple polynomial QS [<a href="Applied%20Cryptography_split_035.html#r66" class="calibre5 pcalibre">66</a>] by a team of
mathematicians led by Lenstra. Volunteers on the Internet carried out the
computation: 600 people and 1600 machines over the course of eight months,
probably the largest ad hoc multiprocessor ever assembled. The calculation
was the equivalent of 4000 to 6000 mips-years. The machines communicated
via electronic mail, sending their individual results to a central repository
where the final steps of analysis took place. This computation used the QS and
five-year-old theory; it would have taken one-tenth the time using the NFS
[<a href="Applied%20Cryptography_split_036.html#r949" class="calibre5 pcalibre">949</a>]. According to [<a href="Applied%20Cryptography_split_035.html#r66" class="calibre5 pcalibre">66</a>]: “We conclude that commonly used 512-bit RSA
moduli are vulnerable to any organization prepared to spend a few million
dollars and to wait a few months.” They estimate that factoring a 512-bit
number would be 100 times harder using the same technology, and only 10
times harder using the NFS and current technology [<a href="Applied%20Cryptography_split_036.html#r949" class="calibre5 pcalibre">949</a>].</p>

<p class="calibre9">To keep up on the state of the art of factoring, RSA Data Security, Inc. set up
the RSA Factoring Challenge in March 1991 [<a href="Applied%20Cryptography_split_035.html#r532" class="calibre5 pcalibre">532</a>]. The challenge consists of a
list of hard numbers, each the product of two primes of roughly equal size.
Each prime was chosen to be congruent to 2 modulo 3. There are 42 numbers
in the challenge, one each of length 100 digits through 500 digits in steps of 10
digits (plus one additional number, 129 digits long). At the time of writing,
RSA-100, RSA-110, RSA-120, and RSA-129 have been factored, all using the
QS. RSA-130 might be next (using the NFS), or the factoring champions
might skip directly to RSA-140.</p>

<p class="calibre9">This is a fast-moving field. It is difficult to extrapolate factoring technology
because no one can predict advances in mathematical theory. Before the NFS
was discovered, many people conjectured that the QS was asymptotically as
fast as any factoring method could be. They were wrong.</p>

<p class="calibre9">Near-term advances in the NFS are likely to come in the form of bringing
down the constant: 1.923. Some numbers of a special form, like Fermat
numbers, have a constant more along the lines of 1.5 [<a href="Applied%20Cryptography_split_036.html#r955" class="calibre5 pcalibre">955</a>,<a href="Applied%20Cryptography_split_036.html#r954" class="calibre5 pcalibre">954</a>]. If the hard
numbers used in public-key cryptography had that kind of constant, 1024-bit
numbers could be factored today. One way to lower the constant is to find
better ways of representing numbers as polynomials with small coefficients.
The problem hasn’t been studied very extensively yet, but it is probable that
advances are coming [<a href="Applied%20Cryptography_split_036.html#r949" class="calibre5 pcalibre">949</a>].</p>

<p class="calibre9">For the most current results from the RSA Factoring Challenge, send e-mail to
challenge-info@rsa.com.</p>

<h4 class="calibre8">Square Roots Modulo n</h4>

<p class="calibre9">If <i class="calibre12">n</i> is the product of two primes, then the ability to calculate square roots mod <i class="calibre12">n</i> is computationally equivalent to the ability to factor <i class="calibre12">n</i> [<a href="Applied%20Cryptography_split_036.html#r1283" class="calibre5 pcalibre">1283</a>,<a href="Applied%20Cryptography_split_035.html#r35" class="calibre5 pcalibre">35</a>,<a href="Applied%20Cryptography_split_035.html#r36" class="calibre5 pcalibre">36</a>,<a href="Applied%20Cryptography_split_035.html#r193" class="calibre5 pcalibre">193</a>]. In other words, someone who knows the prime factors of <i class="calibre12">n</i> can easily compute
the square roots of a number mod <i class="calibre12">n</i>, but for everyone else the computation has
been proven to be as hard as computing the prime factors of <i class="calibre12">n. </i></p>

<h3 id="11.5" class="calibre7">11.5 Prime Number Generation</h3>

<p class="calibre9">Public-key algorithms need prime numbers. Any reasonably sized network
needs lots of them. Before discussing the mathematics of prime number
generation, I will answer a few obvious questions.</p>

<ol class="calibre17">

<li class="calibre14">If everyone needs a different prime number, won’t we run out? No.
In fact, there are approximately 10<sup class="calibre19">151</sup> primes 512 bits in length or less.
For numbers near <i class="calibre12">n</i>, the probability that a random number is prime is
approximately one in ln <i class="calibre12">n</i>. So the total number of primes less than <i class="calibre12">n</i> is <i class="calibre12">n</i>/(ln <i class="calibre12">n</i>). 
There are only 10<sup class="calibre19">77</sup> atoms in the universe. If every atom in the
universe needed a billion new primes every microsecond from the
beginning of time until now, you would only need 10<sup class="calibre19">109</sup> primes; there
would still be approximately 10<sup class="calibre19">151</sup> 512-bit primes left.
</li>
<li class="calibre14">What if two people accidentally pick the same prime number? It
won’t happen. With over 10<sup class="calibre19">151</sup> prime numbers to choose from, the odds
of that happening are significantly less than the odds of your computer
spontaneously combusting at the exact moment you win the lottery.
</li>
<li class="calibre14">If someone creates a database of all primes, won’t he be able to use
that database to break public-key algorithms? Yes, but he can’t do it. If
you could store one gigabyte of information on a drive weighing one
gram, then a list of just the 512-bit primes would weigh so much that it
would exceed the Chandrasekhar limit and collapse into a black hole...so
you couldn’t retrieve the data anyway.
</li>

</ol>

<p class="calibre9">But if factoring numbers is so hard, how can generating prime numbers be
easy? The trick is that the yes/no question, “Is <i class="calibre12">n</i> prime?” is a much easier
question to answer than the more complicated question, “What are the factors
of <i class="calibre12">n? </i> ”</p>

<p class="calibre9">The wrong way to find primes is to generate random numbers and then try to
factor them. The right way is to generate random numbers and test if they are
prime. There are several probabilistic primality tests; tests that determine
whether a number is prime with a given degree of confidence. Assuming this
“degree of confidence” is large enough, these sorts of tests are good enough.
I’ve heard primes generated in this manner called “industrial-grade primes”:
These are numbers that are probably prime with a controllably small chance of
error.</p>

<p class="calibre9">Assume a test is set to fail once in 2<sup class="calibre19">50</sup> tries. This means that there is a 1 in 10<sup class="calibre19">15</sup>
chance that the test falsely indicates that a composite number is prime. (The
test will never falsely indicate that a prime number is composite.) If for some
reason you need more confidence that the number is prime, you can set the
failure level even lower. On the other hand, if you consider that the odds of the
number being composite are 300 million times less than the odds of winning
top prize in a state lottery, you might not worry about it so much.</p>

<p class="calibre9">Overviews of recent developments in the field can be found in [<a href="Applied%20Cryptography_split_036.html#r1256" class="calibre5 pcalibre">1256</a>,<a href="Applied%20Cryptography_split_035.html#r206" class="calibre5 pcalibre">206</a>].
Other important papers are [<a href="Applied%20Cryptography_split_036.html#r1490" class="calibre5 pcalibre">1490</a>,<a href="Applied%20Cryptography_split_035.html#r384" class="calibre5 pcalibre">384</a>,<a href="Applied%20Cryptography_split_035.html#r11" class="calibre5 pcalibre">11</a>,<a href="Applied%20Cryptography_split_035.html#r19" class="calibre5 pcalibre">19</a>,<a href="Applied%20Cryptography_split_035.html#r626" class="calibre5 pcalibre">626</a>,<a href="Applied%20Cryptography_split_035.html#r651" class="calibre5 pcalibre">651</a>,<a href="Applied%20Cryptography_split_036.html#r911" class="calibre5 pcalibre">911</a>].</p>

<h4 class="calibre8">Solovay-Strassen</h4>

<p class="calibre9">Robert Solovay and Volker Strassen developed a probabilistic primality testing
algorithm [<a href="Applied%20Cryptography_split_036.html#r1490" class="calibre5 pcalibre">1490</a>]. Their algorithm uses the Jacobi symbol to test if <i class="calibre12">p</i> is prime:</p>

<ol class="calibre17">

<li class="calibre14">Choose a random number, <i class="calibre12">a</i>, less than <i class="calibre12">p. </i>
</li>
<li class="calibre14">If the gcd(<i class="calibre12">a,p</i>) ≠ 1, then <i class="calibre12">p</i> fails the test and is composite.
</li>
<li class="calibre14">Calculate <i class="calibre12">j</i> = <i class="calibre12">a</i><sup class="calibre19">(<i class="calibre22">p</i> - 1)/2</sup> mod <i class="calibre12">p. </i>
</li>
<li class="calibre14">Calculate the Jacobi symbol <i class="calibre12">J</i>(<i class="calibre12">a,p</i>).
</li>
<li class="calibre14">If <i class="calibre12">j</i> ≠ <i class="calibre12">J</i>(<i class="calibre12">a,p</i>), then <i class="calibre12">p</i> is definitely not prime.
</li>
<li class="calibre14">If <i class="calibre12">j</i> = <i class="calibre12">J</i>(<i class="calibre12">a,p</i>), then the likelihood that <i class="calibre12">p</i> is not prime is no more than
50 percent.
</li>

</ol>

<p class="calibre9">A number <i class="calibre12">a</i> that does not indicate that <i class="calibre12">p</i> is definitely not prime is called a <b class="calibre10">witness</b>. If <i class="calibre12">p</i> is composite, the odds of a random <i class="calibre12">a</i> being a witness is no less than 50 percent. Repeat this test <i class="calibre12">t</i> times, with <i class="calibre12">t</i> different random values for <i class="calibre12">a. </i>
The odds of a composite number passing all <i class="calibre12">t</i> tests is no more than one in 2<sup class="calibre19"><i class="calibre22">t</i></sup>.</p>

<h4 class="calibre8">Lehmann</h4>

<p class="calibre9">Another, simpler, test was developed independently by Lehmann [<a href="Applied%20Cryptography_split_036.html#r945" class="calibre5 pcalibre">945</a>]. Here it
tests if <i class="calibre12">p</i> is prime:</p>

<ol class="calibre17">

<li class="calibre14">Choose a random number <i class="calibre12">a</i> less than <i class="calibre12">p. </i>
</li>
<li class="calibre14">Calculate <i class="calibre12">a</i><sup class="calibre19">(<i class="calibre22">p</i> - 1)/2</sup> mod <i class="calibre12">p. </i>
</li>
<li class="calibre14">If <i class="calibre12">a</i><sup class="calibre19">(<i class="calibre22">p</i> - 1)/2</sup> ≠ 1 or - 1 (mod <i class="calibre12">p</i>), then <i class="calibre12">p</i> is definitely not prime.
</li>
<li class="calibre14">If <i class="calibre12">a</i><sup class="calibre19">(<i class="calibre22">p</i> - 1)/2</sup> ≡ 1 or - 1 (mod <i class="calibre12">p</i>), then the likelihood that <i class="calibre12">p</i> is not prime is no more than 50 percent.
</li>

</ol>

<p class="calibre9">Again, the odds of a random <i class="calibre12">a</i> being a witness to <i class="calibre12">p</i>’s compositeness is no less than 50 percent. Repeat this test <i class="calibre12">t</i> times. If the calculation equals 1 or -1, but does not always equal 1, then <i class="calibre12">p</i> is probably prime with an error rate of 1 in 2<sup class="calibre19"><i class="calibre22">t</i></sup>.</p>

<h4 class="calibre8">Rabin-Miller</h4>

<p class="calibre9">The algorithm everyone uses — it’s easy — was developed by Michael Rabin,
based in part on Gary Miller’s ideas [<a href="Applied%20Cryptography_split_036.html#r1093" class="calibre5 pcalibre">1093</a>,<a href="Applied%20Cryptography_split_036.html#r1284" class="calibre5 pcalibre">1284</a>]. Actually, this is a simplified
version of the algorithm recommended in the DSS proposal [<a href="Applied%20Cryptography_split_036.html#r1149" class="calibre5 pcalibre">1149</a>,<a href="Applied%20Cryptography_split_036.html#r1154" class="calibre5 pcalibre">1154</a>].</p>

<p class="calibre9">Choose a random number, <i class="calibre12">p</i>, to test. Calculate <i class="calibre12">b</i>, where <i class="calibre12">b</i> is the number of times 2 divides <i class="calibre12">p</i> - 1 (i.e., 2<sup class="calibre19"><i class="calibre22">b</i></sup> is the largest power of 2 that divides <i class="calibre12">p</i> - 1). Then calculate <i class="calibre12">m</i>, such that <i class="calibre12">p</i> = 1 + 2<sup class="calibre19"><i class="calibre22">b</i></sup> * <i class="calibre12">m</i>.</p>

<ol class="calibre17">

<li class="calibre14">Choose a random number, <i class="calibre12">a</i>, such that <i class="calibre12">a</i> is less than <i class="calibre12">p. </i>
</li>
<li class="calibre14">Set <i class="calibre12">j</i> = 0 and set <i class="calibre12">z</i> = <i class="calibre12">a<sup class="calibre19">m</sup></i> mod <i class="calibre12">p. </i>
</li>
<li class="calibre14">If <i class="calibre12">z</i> = 1, or if <i class="calibre12">z</i> = <i class="calibre12">p</i> - 1, then <i class="calibre12">p</i> passes the test and may be prime.
</li>
<li class="calibre14">If <i class="calibre12">j</i> &gt; 0 and <i class="calibre12">z</i> = 1, then <i class="calibre12">p</i> is not prime.
</li>
<li class="calibre14">Set <i class="calibre12">j</i> = <i class="calibre12">j</i> + 1. If <i class="calibre12">j</i> &lt; b and <i class="calibre12">z</i> ≠ <i class="calibre12">p</i> - 1, set <i class="calibre12">z</i> = <i class="calibre12">z</i><sup class="calibre19">2</sup> mod <i class="calibre12">p</i> and go back to step (4). If <i class="calibre12">z</i> = p - 1, then <i class="calibre12">p</i> passes the test and may be prime.
</li>
<li class="calibre14">If <i class="calibre12">j</i> = <i class="calibre12">b</i> and <i class="calibre12">z</i> ≠ <i class="calibre12">p</i> - 1, then <i class="calibre12">p</i> is not prime.
</li>

</ol>

<p class="calibre9">The odds of a composite passing decreases faster with this test than with
previous ones. Three-quarters of the possible values of <i class="calibre12">a</i> are guaranteed to be witnesses. This means that a composite number will slip through <i class="calibre12">t</i> tests no
more than ¼<sup class="calibre19"><i class="calibre22">t</i></sup> of the time, where <i class="calibre12">t</i> is the number of iterations. Actually, these numbers are very pessimistic. For most random numbers, something like 99.9
percent of the possible <i class="calibre12">a</i> values are witnesses [<a href="Applied%20Cryptography_split_035.html#r96" class="calibre5 pcalibre">96</a>].</p>

<p class="calibre9">There are even better estimations [<a href="Applied%20Cryptography_split_035.html#r417" class="calibre5 pcalibre">417</a>]. For <i class="calibre12">n-</i>bit candidate primes (where <i class="calibre12">n</i> is more than 100), 
the odds of error in one test are less than 1 in 4<i class="calibre12">n</i>2<sup class="calibre19">(<i class="calibre22">k</i>/2)<sup class="calibre66">(1/2)</sup></sup>. 
And for a 256-bit <i class="calibre12">n</i>, the odds of error in six tests are less than 1 in 2<sup class="calibre19">51</sup>. More theory is in [<a href="Applied%20Cryptography_split_035.html#r418" class="calibre5 pcalibre">418</a>].</p>

<h4 class="calibre8">Practical Considerations</h4>

<p class="calibre9">In real-world implementations, prime generation goes quickly.</p>

<ol class="calibre17">

<li class="calibre14">Generate a random <i class="calibre12">n-</i>bit number, <i class="calibre12">p</i>.
</li>
<li class="calibre14">Set the high-order and low-order bit to 1. (The high-order bit
ensures that the prime is of the required length and the low-order bit
ensures that it is odd.)
</li>
<li class="calibre14">Check to make sure <i class="calibre12">p</i> is not divisible by any small primes: 3, 5, 7, 11, and so on. Many implementations test <i class="calibre12">p</i> for divisibility by all primes
less than 256. The most efficient is to test for divisibility by all primes
less than 2000 [<a href="Applied%20Cryptography_split_036.html#r949" class="calibre5 pcalibre">949</a>]. You can do this efficiently using a wheel [<a href="Applied%20Cryptography_split_036.html#r863" class="calibre5 pcalibre">863</a>].
</li>
<li class="calibre14">Perform the Rabin-Miller test for some random <i class="calibre12">a</i>. If <i class="calibre12">p</i> passes, generate another random <i class="calibre12">a</i> and go through the test again. Choose a small
value of <i class="calibre12">a</i> to make the calculations go quicker. Do five tests [<a href="Applied%20Cryptography_split_035.html#r651" class="calibre5 pcalibre">651</a>]. (One
might seem like enough, but do five.) If <i class="calibre12">p</i> fails one of the tests, generate
another <i class="calibre12">p</i> and try again.
</li>

</ol>

<p class="calibre9">Another option is not to generate a random <i class="calibre12">p</i> each time, but to incrementally
search through numbers starting at a random point until you find a prime.</p>

<p class="calibre9">Step (3) is optional, but it is a good idea. Testing a random odd <i class="calibre12">p</i> to make sure it is not divisible by 3, 5, and 7 eliminates 54 percent of the odd numbers
before you get to step (4). Testing against all primes less than 100 eliminates
76 percent of the odd numbers; testing against all primes less than 256
eliminates 80 percent. In general, the fraction of odd candidates that is not a
multiple of any prime less than <i class="calibre12">n</i> is 1.12/ln <i class="calibre12">n.</i> The larger the <i class="calibre12">n</i> you test up to, the more precomputation is required before you get to the Rabin-Miller test.</p>

<p class="calibre9">One implementation of this method on a Sparc II was able to find 256-bit
primes in an average of 2.8 seconds, 512-bit primes in an average of 24.0
seconds, 768-bit primes in an average of 2.0 minutes, and 1024-bit primes in
an average of 5.1 minutes [<a href="Applied%20Cryptography_split_036.html#r918" class="calibre5 pcalibre">918</a>].</p>

<h4 class="calibre8">Strong Primes</h4>

<p class="calibre9">If <i class="calibre12">n</i> is the product of two primes, <i class="calibre12">p</i> and <i class="calibre12">q</i>, it may be desirable to use <b class="calibre10">strong</b> <b class="calibre10">primes</b> for <i class="calibre12">p</i> and <i class="calibre12">q</i>. These are prime numbers with certain properties that make the product <i class="calibre12">n</i> difficult to factor by specific factoring methods. Among the
properties suggested have been [<a href="Applied%20Cryptography_split_036.html#r1328" class="calibre5 pcalibre">1328</a>,<a href="Applied%20Cryptography_split_035.html#r651" class="calibre5 pcalibre">651</a>]:</p>

<p class="quote">The greatest common divisor of <i class="calibre12">p</i> - 1 and <i class="calibre12">q</i> - 1 should be small. <br class="calibre3"/>
Both <i class="calibre12">p</i> - 1 and <i class="calibre12">q</i> - 1 should have large prime factors, respectively <i class="calibre12">p’</i> and <i class="calibre12">q’</i>. <br class="calibre3"/>
Both <i class="calibre12">p’</i> - 1 and <i class="calibre12">q’</i> - 1 should have large prime factors. <br class="calibre3"/>
Both <i class="calibre12">p</i> + 1 and <i class="calibre12">q</i> + 1 should have large prime factors. <br class="calibre3"/>
Both (<i class="calibre12">p</i> - 1)/2 and (<i class="calibre12">q</i> - 1)/2 should be prime [<a href="Applied%20Cryptography_split_035.html#r182" class="calibre5 pcalibre">182</a>]. (Note that if this condition is true, then so are the first two.)</p>

<p class="calibre9">Whether strong primes are necessary is a subject of debate. These properties
were designed to thwart some older factoring algorithms. However, the fastest
factoring algorithms have as good a chance of factoring numbers that meet
these criteria as they do of factoring numbers that do not [<a href="Applied%20Cryptography_split_036.html#r831" class="calibre5 pcalibre">831</a>].</p>

<p class="calibre9">I recommend against specifically generating strong primes. The length of the
primes is much more important than the structure. Moreover, structure may be
damaging because it is less random.</p>

<p class="calibre9">This may change. New factoring techniques may be developed that work better
on numbers with certain properties than on numbers without them. If so, strong
primes may be required once again. Check current theoretical mathematics
journals for updates.</p>

<h3 id="11.6" class="calibre7">11.6 Discrete Logarithms in a Finite Field</h3>

<p class="calibre9">Modular exponentiation is another one-way function used frequently in
cryptography. Evaluating this expression is easy:</p>

<p class="math"><i class="calibre12">a<sup class="calibre19">x</sup></i> mod <i class="calibre12">n</i>
</p>

<p class="calibre9">The inverse problem of modular exponentiation is that of finding the discrete
logarithm of a number. This is a hard problem:</p>

<p class="math">Find <i class="calibre12">x</i> where <i class="calibre12">a<sup class="calibre19">x</sup></i> ≡ <i class="calibre12">b</i> (mod <i class="calibre12">n</i>).
</p>

<p class="calibre9">For example:</p>

<p class="math">If 3<sup class="calibre19"><i class="calibre22">x</i></sup> ≡ 15 mod 17, then <i class="calibre12">x</i> = 6
</p>

<p class="calibre9">Not all discrete logarithms have solutions (remember, the only valid solutions
are integers). It’s easy to see that there is no solution, <i class="calibre12">x</i>, to the equation</p>

<p class="math">3<sup class="calibre19"><i class="calibre22">x</i></sup> = 7 (mod 13)
</p>

<p class="calibre9">It’s far more difficult to solve these problems using 1024-bit numbers.</p>

<h4 class="calibre8">Calculating Discrete Logarithms in a Finite Group</h4>

<p class="calibre9">There are three main groups whose discrete logarithms are of interest to
cryptographers:</p>

<ul class="calibre13">

<li class="calibre14">The multiplicative group of prime fields: GF(<i class="calibre12">p</i>)
</li>
<li class="calibre14">The multiplicative group of finite fields of characteristic 2: GF(2<sup class="calibre19"><i class="calibre22">n</i></sup>)
</li>
<li class="calibre14">Elliptic curve groups over finite fields <i class="calibre12">F</i> : EC(<i class="calibre12">F</i>)
</li>

</ul>

<p class="calibre9">The security of many public-key algorithms is based on the problem of finding
discrete logarithms, so the problem has been extensively studied. A good
comprehensive overview of the problem, and the best solutions at the time, can
be found in [<a href="Applied%20Cryptography_split_036.html#r1189" class="calibre5 pcalibre">1189</a>,<a href="Applied%20Cryptography_split_036.html#r1039" class="calibre5 pcalibre">1039</a>]. The best current article on the topic is [<a href="Applied%20Cryptography_split_036.html#r934" class="calibre5 pcalibre">934</a>].</p>

<p class="calibre9">If <i class="calibre12">p</i> is the modulus and is prime, then the complexity of finding discrete
logarithms in GF(<i class="calibre12">p</i>) is essentially the same as factoring an integer <i class="calibre12">n</i> of about the same size, when <i class="calibre12">n</i> is the product of two approximately equal-length primes
[<a href="Applied%20Cryptography_split_036.html#r1378" class="calibre5 pcalibre">1378</a>,<a href="Applied%20Cryptography_split_036.html#r934" class="calibre5 pcalibre">934</a>]. This is:</p>

<p class="math">e<sup class="calibre19">(1 + O(1))(ln(<i class="calibre22">p</i>))<sup class="calibre66">(1/2)</sup>(ln(ln(<i class="calibre22">p</i>)))<sup class="calibre66">(1/2)</sup></sup>
</p>

<p class="calibre9">The number field sieve is faster, with an heuristic asymptotic time estimate of</p>

<p class="math">e<sup class="calibre19">(1.923 + O(1))(ln(<i class="calibre22">p</i>))<sup class="calibre66">(1/3)</sup>(ln(ln(<i class="calibre22">p</i>)))<sup class="calibre66">(2/3)</sup></sup>
</p>

<p class="calibre9">Stephen Pohlig and Martin Hellman found a fast way of computing discrete
logarithms in GF(<i class="calibre12">p</i>) if <i class="calibre12">p</i> - 1 has only small prime factors [<a href="Applied%20Cryptography_split_036.html#r1253" class="calibre5 pcalibre">1253</a>]. For this reason, only fields where <i class="calibre12">p</i> - 1 has at least one large factor are used in
cryptography. Another algorithm [<a href="Applied%20Cryptography_split_035.html#r14" class="calibre5 pcalibre">14</a>] computes discrete logarithms at a speed
comparable to factoring; it has been expanded to fields of the form GF(<i class="calibre12">p<sup class="calibre19">n</sup></i>)
[<a href="Applied%20Cryptography_split_035.html#r716" class="calibre5 pcalibre">716</a>]. This algorithm was criticized [<a href="Applied%20Cryptography_split_035.html#r727" class="calibre5 pcalibre">727</a>] for having some theoretical
problems. Other articles [<a href="Applied%20Cryptography_split_036.html#r1588" class="calibre5 pcalibre">1588</a>] show how difficult the problem really is.</p>

<p class="calibre9">Computing discrete logarithms is closely related to factoring. If you can solve
the discrete logarithm problem, then you can factor. (The converse has never
been proven to be true.) Currently, there are three methods for calculating
discrete logarithms in a prime field [<a href="Applied%20Cryptography_split_035.html#r370" class="calibre5 pcalibre">370</a>,<a href="Applied%20Cryptography_split_036.html#r934" class="calibre5 pcalibre">934</a>,<a href="Applied%20Cryptography_split_035.html#r648" class="calibre5 pcalibre">648</a>]: the linear sieve, the
Gaussian integer scheme, and the number field sieve.</p>

<p class="calibre9">The preliminary, extensive computing has to be done only once per field.
Afterward, individual logarithms can be quickly calculated. This can be a
security disadvantage for systems based on these fields. It is important that
different applications use different prime fields. Multiple users in the same
application can use a common field, though.</p>

<p class="calibre9">In the world of extension fields, GF(2<sup class="calibre19"><i class="calibre22">n</i></sup>) hasn’t been ignored by researchers. An
algorithm was proposed in [<a href="Applied%20Cryptography_split_035.html#r727" class="calibre5 pcalibre">727</a>]. Coppersmith’s algorithm makes finding
discrete logarithms in fields such as GF(2<sup class="calibre19">127</sup>) reasonable and finding them in
fields around GF(2<sup class="calibre19">400</sup>) possible [<a href="Applied%20Cryptography_split_035.html#r368" class="calibre5 pcalibre">368</a>]. This was based on work in [<a href="Applied%20Cryptography_split_035.html#r180" class="calibre5 pcalibre">180</a>]. The
precomputation stage of this algorithm is enormous, but otherwise it is nice
and efficient. A practical implementation of a less efficient version of the same
algorithm, after a seven-hour precomputation period, found discrete logs in
GF(2<sup class="calibre19">127</sup>) in several seconds each [<a href="Applied%20Cryptography_split_036.html#r1130" class="calibre5 pcalibre">1130</a>,<a href="Applied%20Cryptography_split_035.html#r180" class="calibre5 pcalibre">180</a>]. (This particular field, once used
in some cryptosystems [<a href="Applied%20Cryptography_split_035.html#r142" class="calibre5 pcalibre">142</a>,<a href="Applied%20Cryptography_split_036.html#r1631" class="calibre5 pcalibre">1631</a>,<a href="Applied%20Cryptography_split_036.html#r1632" class="calibre5 pcalibre">1632</a>], is insecure.) For surveys of some of
these results, consult [<a href="Applied%20Cryptography_split_036.html#r1189" class="calibre5 pcalibre">1189</a>,<a href="Applied%20Cryptography_split_036.html#r1039" class="calibre5 pcalibre">1039</a>].</p>

<p class="calibre9">More recently, the precomputations for GF(2<sup class="calibre19">227</sup>), GF(2<sup class="calibre19">313</sup>), and GF(2<sup class="calibre19">401</sup>) are
done, and significant progress has been made towards GF(2<sup class="calibre19">503</sup>). These
calculations are being executed on an nCube-2 massively parallel computer
with 1024 processors [<a href="Applied%20Cryptography_split_035.html#r649" class="calibre5 pcalibre">649</a>,<a href="Applied%20Cryptography_split_035.html#r650" class="calibre5 pcalibre">650</a>]. Computing discrete logarithms in GF(2<sup class="calibre19">593</sup>) is
still barely out of reach.</p>

<p class="calibre9">Like discrete logarithms in a prime field, the precomputation required to
calculate discrete logarithms in a polynomial field has to be done only once.
Taher ElGamal [<a href="Applied%20Cryptography_split_035.html#r520" class="calibre5 pcalibre">520</a>] gives an algorithm for calculating discrete logs in the
field GF(<i class="calibre12">p</i><sup class="calibre19">2</sup>).</p>

<div class="calibre6" id="calibre_pb_28"></div>
</div>






</body></html>
