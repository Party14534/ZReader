<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Applied Cryptography, Second Edition: Protocols, Algorithms, and Source Code in C</title>
    <meta content="Bruce Schneier" name="author"/>
    <meta content="An introduction to cryptography." name="description"/>
    <meta content="programming,cryptography" name="keywords"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body class="calibre">
<div id="book" class="calibre1">
<h1 class="chapter" id="25">Chapter 25 <br class="calibre3"/>
Politics</h1>

<h3 id="25.1" class="calibre7">25.1 National Security Agency (NSA)</h3>

<p class="calibre9">The NSA is the National Security Agency (once called “No Such Agency” or
“Never Say Anything,” but they’ve been more open recently), the official
security body of the U.S. government. President Harry Truman created the
agency in 1952 under the Department of Defense, and for many years its very
existence was kept secret. The NSA is concerned with signals intelligence; its
mandate is to listen in on and decode all foreign communications of interest to
the security of the United States.</p>

<p class="calibre9">The following paragraphs are excerpted from NSA’s original charter, signed
by President Truman in 1952, and classified for many years thereafter [<a href="Applied%20Cryptography_split_036.html#r1535" class="calibre5 pcalibre">1535</a>]:</p>

<p class="quote">The COMINT mission of the National Security Agency (NSA)
shall be to provide an effective, unified organization and control
of the communications intelligence activities of the United States
conducted against foreign governments, to provide for integrated
operational policies and procedures pertaining thereto. As used in
this directive, the terms “communications intelligence” or
“COMINT” shall be construed to mean all procedures and
methods used in the interception of communications other than
foreign press and propaganda broadcasts and the obtaining of
information from such communications by other than intended
recipients, but shall exclude censorship and the production and
dissemination of finished intelligence.
<br class="calibre3"/><br class="calibre3"/>
The special nature of COMINT actives requires that they be
treated in all respects as being outside the framework of other or
general intelligence activities. Orders, directives, policies, or
recommendations of any authority of the Executive Branch
relating to the collection, production, security, handling,
dissemination, or utilization of intelligence, and/or classified
material, shall not be applicable to COMINT actives, unless
specifically so stated and issued by competent department or
agency authority represented on the Board. Other National
Security Council Intelligence Directives to the Director of Central
Intelligence and related implementing directives issued by the
Director of Central Intelligence shall be construed as
non-applicable to COMINT activities, unless the National
Security Council has made its directive specifically applicable to
COMINT.</p>

<p class="calibre9">NSA conducts research in cryptology, both in designing secure algorithms to
protect U.S. communications and in designing cryptanalytic techniques to
listen in on non-U.S. communications. The NSA is known to be the largest
employer of mathematicians in the world; it is also the largest purchaser of
computer hardware in the world. The NSA probably possesses cryptographic
expertise many years ahead of the public state of the art (in algorithms, but
probably not in protocols) and can undoubtedly break many of the systems
used in practice. But, for reasons of national security, almost all information
about the NSA — even its budget — is classified. (Its budget is rumored to be
$13 billion per year — including military funding of NSA projects and
personnel — and it is rumored to employ 16,000 people.)</p>

<p class="calibre9">The NSA uses its power to restrict the public availability of cryptography, so
as to prevent national enemies from employing encryption methods too strong
for the NSA to break. James Massey discusses this struggle between academic
and military research in cryptography [<a href="Applied%20Cryptography_split_036.html#r1007" class="calibre5 pcalibre">1007</a>]:</p>

<p class="quote">If one regards cryptology as the prerogative of government, one
accepts that most cryptologic research will be conducted behind
closed doors. Without doubt, the number of workers engaged
today in such secret research in cryptology far exceeds that of
those engaged in open research in cryptology. For only about 10
years has there in fact been widespread open research in
cryptology. There have been, and will continue to be, conflicts
between these two research communities. Open research is a
common quest for knowledge that depends for its vitality on the
open exchange of ideas via conference presentations and
publications in scholarly journals. But can a government agency,
charged with responsibilities of breaking the ciphers of other
nations, countenance the publication of a cipher that it cannot
break? Can a researcher in good conscience publish such a cipher
that might undermine the effectiveness of his own government’s
code-breakers? One might argue that publication of a provably
secure cipher would force all governments to behave like
Stimson’s “gentlemen,” but one must be aware that open research
in cryptography is fraught with political and ethical
considerations of a severity more than in most scientific fields.
The wonder is not that some conflicts have occurred between
government agencies and open researchers in cryptology, but
rather that these conflicts (at least those of which we are aware)
have been so few and so mild.</p>

<p class="calibre9">James Bamford wrote a fascinating book about the NSA: <i class="calibre12">The Puzzle Palace</i>
[<a href="Applied%20Cryptography_split_035.html#r79" class="calibre5 pcalibre">79</a>], recently updated by Bamford and Wayne Madsen [<a href="Applied%20Cryptography_split_035.html#r80" class="calibre5 pcalibre">80</a>].</p>

<h4 class="calibre8">The Commercial COMSEC Endorsement Program (CCEP)</h4>

<p class="calibre9">The Commercial COMSEC Endorsement Program (CCEP), codenamed
Overtake, is a 1984 NSA initiative to facilitate the development of computer
and communications products with embedded cryptography [<a href="Applied%20Cryptography_split_035.html#r85" class="calibre5 pcalibre">85</a>,<a href="Applied%20Cryptography_split_036.html#r1165" class="calibre5 pcalibre">1165</a>]. The
military had always paid for this kind of thing for themselves, and it was very
expensive. The NSA figured that if companies could sell equipment to both the
military and to corporate users, even overseas, costs would go down and
everyone would benefit. They would no longer endorse equipment as
complying with Federal Standard 1027, and then CCEP would provide
government-endorsed cryptographic equipment [<a href="Applied%20Cryptography_split_035.html#r419" class="calibre5 pcalibre">419</a>].</p>

<p class="calibre9">NSA developed a series of cryptographic modules for different purposes.
Different algorithms would be used in the modules for different applications,
and manufacturers would be able to pull one module out and plug in another
depending on the customer. There were modules for military use (Type I),
modules for “unclassified but sensitive” government use (Type II), modules
for corporate use (Type III), and modules for export (Type IV). Table 25.1
summarizes the different modules, applications, and names.</p>

<table class="data-table1" id="table-25-1">
<caption class="calibre67">Table 25.1 - CCEP Modules</caption>
<tbody class="calibre24"><tr class="calibre68">
<th class="calibre26">Application</th>
<th class="calibre26">Type I</th>
<th class="calibre26">Type II</th>
</tr>
<tr class="calibre25"><td class="calibre61">Voice/low-speed data</td><td class="calibre61">Winster</td><td class="calibre61">Edgeshot</td></tr>
<tr class="calibre25"><td class="calibre61">Computer</td><td class="calibre61">Tepache</td><td class="calibre61">Bulletproof</td></tr>
<tr class="calibre71"><td class="calibre78">High-speed data</td><td class="calibre78">Foresee</td><td class="calibre78">Brushstroke</td></tr>
<tr class="calibre25"><td class="calibre61">Next Generation</td><td class="calibre61">Countersign I</td><td class="calibre61">Countersign II</td></tr>
</tbody></table>

<p class="calibre39">This program is still around, but never became popular outside the
government. All the modules were tamperproof, all the algorithms were
classified, and you had to get your keys from NSA. Corporations never really
bought into the idea of using classified algorithms dictated by the government.
You’d think the NSA would have learned from this lesson and not even
bothered with Clipper, Skipjack, and escrowed encryption chips.</p>

<h3 id="25.2" class="calibre7">25.2 National Computer Security Center (NCSC)</h3>

<p class="calibre9">The National Computer Security Center, a branch of the NSA, is responsible
for the government’s trusted computer program. Currently, the center
evaluates commercial security products (both hardware and software),
sponsors and publishes research, develops technical guidelines, and generally
provides advice, support, and training.</p>

<p class="calibre9">The NCSC publishes the infamous “Orange Book” [<a href="Applied%20Cryptography_split_035.html#r465" class="calibre5 pcalibre">465</a>]. Its actual title is the
 <i class="calibre12">Department of Defense Trusted Computer System Evaluation Criteria</i>, but
that’s a mouthful to say and the book has an orange cover. The Orange Book
attempts to define security requirements, gives computer manufacturers an
objective way to measure the security of their systems, and guides them as to
what to build into their secure products. It focuses on computer security and
doesn’t really say a lot about cryptography.</p>

<p class="calibre9">The Orange Book defines four broad divisions of security protection. It also
defines classes of protection within some of those divisions. They are
summarized in Table 25.2.</p>

<p id="table-25-2" class="calibre9"><b class="calibre10">Table 25.2 - Orange Book Classifications</b></p>
<hr class="calibre63"/>
<p class="math-left">D: Minimal Security
C: Discretionary Protection
        C1: Discretionary Security Protection
        C2: Controlled Access Protection
B: Mandatory Protection
        B1: Labeled Security Protection
        B2: Structured Protection
        B3: Security Domains
A: Verified Protection
        A1: Verified Design</p>
<hr class="calibre63"/>

<p class="calibre9">Sometimes manufacturers say things like “we have C2 security.” This is what
they’re talking about. For more information on this, read [<a href="Applied%20Cryptography_split_036.html#r1365" class="calibre5 pcalibre">1365</a>]. The computer
security model used in these criteria is called the Bell-LaPadula model
[<a href="Applied%20Cryptography_split_035.html#r100" class="calibre5 pcalibre">100</a>,<a href="Applied%20Cryptography_split_035.html#r101" class="calibre5 pcalibre">101</a>,<a href="Applied%20Cryptography_split_035.html#r102" class="calibre5 pcalibre">102</a>,<a href="Applied%20Cryptography_split_035.html#r103" class="calibre5 pcalibre">103</a>].</p>

<p class="calibre9">The NCSC has published a whole series of books on computer security,
sometimes called the Rainbow Books (all the covers have different colors). For
example, <i class="calibre12">Trusted Network Interpretation of the Trusted Computer System Evaluation Criteria</i> [<a href="Applied%20Cryptography_split_036.html#r1146" class="calibre5 pcalibre">1146</a>], 
sometimes called the “Red Book,” interprets the
Orange Book for networks and network equipment. The <i class="calibre12">Trusted Database Management System Interpretation of the Trusted Computer System Evaluation Criteria</i> 
[<a href="Applied%20Cryptography_split_036.html#r1147" class="calibre5 pcalibre">1147</a>] — I can’t even begin to describe the color of that
cover — does the same for databases. There are now over 30 of these books,
some with hideously colored covers.</p>

<p class="calibre9">For a complete set of the Rainbow Books, write <code class="calibre18">Director, National Security
Agency, INFOSEC Awareness, Attention: C81, 9800 Savage Road, Fort
George G. Meade, MD 20755-6000; (410) 766-8729</code>. Don’t tell them I sent
you.</p>

<h3 id="25.3" class="calibre7">25.3 National Institute of Standards and Technology (NIST)</h3>

<p class="calibre9">The NIST is the National Institute of Standards and Technology, a division of
the U.S. Department of Commerce. Formerly the NBS (National Bureau of
Standards), it changed its name in 1988. Through its Computer Systems
Laboratory (CSL), NIST promotes open standards and interoperability that it
hopes will spur the economic development of computer-based industries. To
this end, NIST issues standards and guidelines that it hopes will be adopted by
all computer systems in the United States. Official standards are published as
FIPS (Federal Information Processing Standards) publications.</p>

<p class="calibre9">If you want copies of any FIPS (or any other NIST publication), contact
<code class="calibre18">National Technical Information Service (NTIS), U.S. Department of
Commerce, 5285 Port Royal Road, Springfield, VA 22161; (703) 487-4650;</code> or
visit <code class="calibre18">gopher://csrc.ncsl.nist.gov</code>.</p>

<p class="calibre9">When Congress passed the Computer Security Act of 1987, NIST was
mandated to define standards for ensuring the security of sensitive but
unclassified information in government computer systems. (Classified
information and Warner Amendment data are under the jurisdiction of the
NSA.) The Act authorizes NIST to work with other government agencies and
private industry in evaluating proposed technology standards.</p>

<p class="calibre9">NIST issues standards for cryptographic functions. U.S. government agencies
are required to use them for sensitive but unclassified information. Often the
private sector adopts these standards as well. NIST issued DES, DSS, SHS,
and EES.</p>

<p class="calibre9">All these algorithms were developed with some help from the NSA, ranging
from analyzing DES to designing DSS, SHS, and the Skipjack algorithm in
EES. Some people have criticized NIST for allowing the NSA to have too
much control over these standards, since the NSA’s interests may not coincide
with those of NIST. It is unclear how much actual influence NSA has on the
design and development of the algorithms. Given NIST’s limited staff, budget,
and resources, NSA’s involvement is probably considerable. NSA has
significant resources to contribute, including a computer facility
second-to-none.</p>

<p class="calibre9">The official “Memorandum of Understanding” (MOU) between the two
agencies reads:</p>

<p class="quote">MEMORANDUM OF UNDERSTANDING BETWEEN THE
DIRECTOR OF THE NATIONAL INSTITUTE OF
STANDARDS AND TECHNOLOGY AND THE DIRECTOR
OF THE NATIONAL SECURITY AGENCY CONCERNING
THE IMPLEMENTATION OF PUBLIC LAW 100-235
<br class="calibre3"/><br class="calibre3"/>
Recognizing that:

</p><ol class="calibre94">

<li class="calibre14">Under Section 2 of the Computer Security Act of 1987
(Public Law 100-235), (the Act), the National Institute of
Standards and Technology (NIST) has the responsibility
within the Federal Government for:

<ol class="calibre95">

<li class="calibre14">Developing technical, management, physical, and
administrative standards and guidelines for the
cost-effective security and privacy of sensitive information
in Federal computer systems as defined in the Act; and,</li>
<li class="calibre14">Drawing on the computer system technical security
guidelines of the National Security Agency (NSA) in this
regard where appropriate.
</li>

</ol>
</li>

<li class="calibre14">Under Section 3 of the Act, the NIST is to coordinate
closely with other agencies and offices, including the NSA,
to assure:
<ol class="calibre95">

<li class="calibre14">Maximum use of all existing and planned programs,
materials, studies, and reports relating to computer systems
security and privacy, in order to avoid unnecessary and
costly duplication of effort; and,</li>
<li class="calibre14">To the maximum extent feasible, that standards
developed by the NIST under the Act are consistent and
compatible with standards and procedures developed for
the protection of classified information in Federal computer
systems.
</li>

</ol>
</li>

<li class="calibre14">Under the Act, the Secretary of Commerce has the
responsibility, which he has delegated to the Director of
NIST, for appointing the members of the Computer System
Security and Privacy Advisory Board, at least one of whom
shall be from the NSA.
Therefore, in furtherance of the purposes of this MOU, the
Director of the NIST and the Director of the NSA hereby agree as
follows:

<ol class="calibre96">

<li class="calibre14">The NIST will:
<ol class="calibre95">

<li class="calibre14">Appoint to the Computer Security and Privacy Advisory
Board at least one representative nominated by the Director
of the NSA.</li>
<li class="calibre14">Draw upon computer system technical security
guidelines developed by the NSA to the extent that the
NIST determines that such guidelines are consistent with
the requirements for protecting sensitive information in
Federal computer systems.</li>
<li class="calibre14">Recognize the NSA-certified rating of evaluated trusted
systems under the Trusted Computer Security Evaluation
Criteria Program without requiring additional evaluation.</li>
<li class="calibre14">Develop telecommunications security standards for
protecting sensitive unclassified computer data, drawing
upon the expertise and products of the National Security
Agency, to the greatest extent possible, in meeting these
responsibilities in a timely and cost-effective manner.</li>
<li class="calibre14">Avoid duplication where possible in entering into
mutually agreeable arrangements with the NSA for the
NSA support.</li>
<li class="calibre14">Request the NSA’s assistance on all matters related to
cryptographic algorithms and cryptographic techniques
including but not limited to research, development
evaluation, or endorsement.
</li>

</ol>
</li>

<li class="calibre14">The NSA will:
<ol class="calibre95">

<li class="calibre14">Provide the NIST with technical guidelines in trusted
technology, telecommunications security, and personal
identification that may be used in cost-effective systems for
protecting sensitive computer data.</li>
<li class="calibre14">Conduct or initiate research and development programs
in trusted technology, telecommunications security,
cryptographic techniques and personal identification
methods.</li>
<li class="calibre14">Be responsive to the NIST’s requests for assistance in
respect to all matters related to cryptographic algorithms
and cryptographic techniques including but not limited to
research, development, evaluation, or endorsement.</li>
<li class="calibre14">Establish the standards and endorse products for
application to secure systems covered in 10 USC Section
2315 (the Warner Amendment).</li>
<li class="calibre14">Upon request by Federal agencies, their contractors and
other government-sponsored entities, conduct assessments
of the hostile intelligence threat to federal information
systems, and provide technical assistance and recommend
endorsed products for application to secure systems against
that threat.
</li>

</ol>
</li>

<li class="calibre14">The NIST and the NSA shall:
<ol class="calibre95">

<li class="calibre14">Jointly review agency plans for the security and privacy
of computer systems submitted to NIST and NSA pursuant
to section 6(b) of the Act.</li>
<li class="calibre14">Exchange technical standards and guidelines as
necessary to achieve the purposes of the Act.</li>
<li class="calibre14">Work together to achieve the purposes of this
memorandum with the greatest efficiency possible,
avoiding unnecessary duplication of effort.</li>
<li class="calibre14">Maintain an on-going open dialogue to ensure that each
organization remains abreast of emerging technologies and
issues affecting automated information system security in
computer-based systems.</li>
<li class="calibre14">Establish a Technical Working Group to review and
analyze issues of mutual interest pertinent to protection of
systems that process sensitive or other unclassified
information. The Group shall be composed of six federal
employees, three each selected by NIST and NSA and to be
augmented as necessary by representatives of other
agencies. Issues may be referred to the group by either the
NSA Deputy Director for Information Security or the NIST
Deputy Director or may be generated and addressed by the
group upon approval by the NSA DDI or NIST Deputy
Director. Within days of the referral of an issue to the
Group by either the NSA Deputy Director for Information
Security or the NIST Deputy Director, the Group will
respond with a progress report and plan for further analysis,
if any.</li>
<li class="calibre14">Exchange work plans on an annual basis on all research
and development projects pertinent to protection of systems
that process sensitive or other unclassified information,
including trusted technology, for protecting the integrity
and availability of data, telecommunications security and
personal identification methods. Project updates will be
exchanged quarterly, and project reviews will be provided
by either party upon request of the other party.</li>
<li class="calibre14">Ensure the Technical Working Group reviews prior to
public disclosure all matters regarding technical systems
security techniques to be developed for use in protecting
sensitive information in federal computer systems to ensure
they are consistent with the national security of the United
States. If NIST and NSA are unable to resolve such an
issue within 60 days, either agency may elect to raise the
issue to the Secretary of Defense and the Secretary of
Commerce. It is recognized that such an issue may be
referred to the President through the NSC for resolution.
No action shall be taken on such an issue until it is
resolved.</li>
<li class="calibre14">Specify additional operational agreements in annexes to
this MOU as they are agreed to by NSA and NIST.
</li>

</ol>
</li>

<li class="calibre14">Either party may elect to terminate this MOU upon six
months’ written notice. This MOU is effective upon
approval of both signatories.
</li>
</ol>

</li>
</ol>

/signed/
<br class="calibre3"/><br class="calibre3"/>
RAYMOND G. KAMMER
<br class="calibre3"/>
Acting Director, National Institute of Standards and
Technology, 24 March 1989
<br class="calibre3"/><br class="calibre3"/>
W. O. STUDEMAN
<br class="calibre3"/>
Vice Admiral, U.S. Navy; Director, National Security
Agency, 23 March 1989<p class="calibre9"></p>

<h3 id="25.4" class="calibre7">25.4 RSA Data Security, Inc. </h3>

<p class="calibre9">RSA Data Security, Inc. (RSADSI) was founded in 1982 to develop, license,
and market the RSA patent. It has some commercial products, including a
standalone e-mail security package, and various cryptographic libraries
(available in either source or object form). RSADSI also markets the RC2 and
RC4 symmetric algorithms (see <a href="Applied%20Cryptography_split_016.html#13.8" class="calibre5 pcalibre">Section 13.8</a>). RSA Laboratories, a research
lab associated with RSADSI, performs basic cryptographic research and
provides consulting services.</p>

<p class="calibre9">Anyone interested in either their patents or products should contact <code class="calibre18">Director of
Sales, RSA Data Security, Inc., 100 Marine Parkway, Redwood City, CA
94065; (415) 595-8782; fax: (415) 595-1873</code>.</p>

<h3 id="25.5" class="calibre7">25.5 Public Key Partners</h3>

<p class="calibre9">The five patents in Table 25.3 are held by Public Key Partners (PKP) of
Sunnyvale, California, a partnership between RSADSI and Caro-Kahn,
Inc. — the parent company of Cylink. (RSADSI gets 65 percent of the profits
and Caro-Kahn gets 35 percent.) PKP claims that these patents, and 4,218,582
in particular, apply to <i class="calibre12">all uses</i> of public-key cryptography.</p>

<table class="data-table1" id="table-25-3">
<caption class="calibre67">Table 25.3 - Public Key Partners’ Patents</caption>
<tbody class="calibre24"><tr class="calibre68">
<th class="calibre26">Patent #</th>
<th class="calibre26">Date</th>
<th class="calibre26">Inventors</th>
<th class="calibre26">Patent Covers</th>
</tr>
<tr class="calibre25"><td class="calibre70">4,200,770</td><td class="calibre70">4/29/80</td><td class="calibre70">Hellman, Diffie, Merkle</td><td class="calibre70">Diffie-Hellman Key Exchange</td></tr>
<tr class="calibre25"><td class="calibre70">4,218,582</td><td class="calibre70">8/19/80</td><td class="calibre70">Hellman, Merkle</td><td class="calibre70">Merkle-Hellman Knapsacks</td></tr>
<tr class="calibre25"><td class="calibre70">4,405,829</td><td class="calibre70">9/20/83</td><td class="calibre70">Rivest, Shamir, Adleman</td><td class="calibre70">RSA</td></tr>
<tr class="calibre71"><td class="calibre72">4,424,414</td><td class="calibre72">3/3/84</td><td class="calibre72">Hellman, Pohlig</td><td class="calibre72">Pohlig-Hellman</td></tr>
<tr class="calibre25"><td class="calibre70">4,995,082</td><td class="calibre70">2/19/91</td><td class="calibre70">Schnorr</td><td class="calibre70">Schnorr Signatures</td></tr>
</tbody></table>

<p class="calibre39">In [<a href="Applied%20Cryptography_split_035.html#r574" class="calibre5 pcalibre">574</a>], PKP wrote:</p>

<p class="quote">These patents [4,200,770, 4,218,582, 4,405,829, and 4,424,414]
cover all known methods of practicing the art of Public Key,
including the variations collectively known as ElGamal.
<br class="calibre3"/><br class="calibre3"/>
Due to the broad acceptance of RSA digital signatures throughout
the international community, Public Key Partners strongly
endorses its incorporation in a digital signature standard. We
assure all interested parties that Public Key Partners will comply
with all of the policies of ANSI and the IEEE concerning the
availability of licenses to practice this art. Specifically, in support
of any RSA signature standard which may be adopted, Public Key
Partners hereby gives its assurance that licenses to practice RSA
signatures will be available under reasonable terms and conditions
on a nondiscriminatory basis.</p>

<p class="calibre9">Whether this is true depends on who you talk to. PKP’s licenses have mostly
been secret, so there is no way to check if the licenses are standard. Although
they claim to have never denied a license to anyone, at least two companies
claim to have been denied a license. PKP guards its patents closely,
threatening anyone who tries to use public-key cryptography without a license.
In part, this is a reaction to U.S. patent law. If you hold a patent and fail to
prosecute an infringement, you can lose your patent. There has been much talk
about whether the patents are legal, but so far it has all been talk. All legal
challenges to PKP’s patents have been settled before judgment.</p>

<p class="calibre9">I am not going to dispense legal advice in this book. Maybe the RSA patent
will not hold up in court. Maybe the patents do not apply to the entirety of
public-key cryptography. (Honestly, I can’t see how they cover ElGamal or
elliptic curve cryptosystems.) Perhaps someone will eventually win a suit
against PKP or RSADSI. But keep in mind that corporations with large legal
departments like IBM, Microsoft, Lotus, Apple, Novell, Digital, National
Semiconductor, AT&amp;T, and Sun have all licensed RSA for use in their
products rather than fight them in court. And Boeing, Shell Oil, DuPont,
Raytheon, and Citicorp have all licensed RSA for their own internal use.</p>

<p class="calibre9">In one case, PKP brought suit against TRW Corporation for using the ElGamal
algorithm without a license. TRW claimed they did not need a license. PKP
and TRW reached a settlement in June 1992. The details of the settlement are
unknown, but they included an agreement by TRW to license the patents. This
does not bode well. TRW can afford good lawyers; I can only assume that if
they thought they could win the suit without spending an unreasonable amount
of money, they would have fought.</p>

<p class="calibre9">Meanwhile, PKP is having its own internal problems. In June 1994 Caro-Kahn
sued RSADSI alleging, among other things, that the RSA patent is invalid and
unenforceable [<a href="Applied%20Cryptography_split_035.html#r401" class="calibre5 pcalibre">401</a>]. Both partners are trying to have the partnership
dissolved. Are the patents valid or not? Will users have to get a license from
Caro-Kahn to use the RSA algorithm? Who will own the Schnorr patent? The
matter will probably be sorted out by the time this book sees publication.</p>

<p class="calibre9">Patents are good for only 17 years, and cannot be renewed. On April 29, 1997,
Diffie-Hellman key exchange (and the ElGamal algorithm) will enter the
public domain. On September 20, 2000, RSA will enter the public domain.
Mark your calendars.</p>

<h3 id="25.6" class="calibre7">25.6 International Association for Cryptologic Research (IACR)</h3>

<p class="calibre9">The International Association for Cryptologic Research is the worldwide
cryptographic research organization. Its stated purpose is to advance the theory
and practice of cryptology and related fields. Membership is open to any
person. The association sponsors two annual conferences, Crypto (held in
Santa Barbara in August) and Eurocrypt (held in Europe in May), and
publishes quarterly <i class="calibre12">The Journal of Cryptology</i> and the <i class="calibre12">IACR Newsletter</i>.</p>

<p class="calibre9">The address of the IACR Business Office changes whenever the president
does. The current address is: <code class="calibre18">IACR Business Office, Aarhus Science Park,
Gustav Wieds Vej 10, DK-8000 Aarhus C, Denmark</code>.</p>

<h3 id="25.7" class="calibre7">25.7 RACE Integrity Primitives Evaluation (RIPE)</h3>

<p class="calibre9">The Research and Development in Advanced Communication Technologies in
Europe (RACE) program was launched by the European Community to
support pre-competitive and pre-normative work in communications standards
and technologies to support Integrated Broadband Communication (IBC). As
part of that effort, RACE established the RACE Integrity Primitives
Evaluation (RIPE) to put together a portfolio of techniques to meet the
anticipated security requirements of IBC.</p>

<p class="calibre9">Six leading European cryptography research groups made up the RIPE
consortium: Center for Mathematics and Computer Science, Amsterdam;
Siemens AG; Philips Crypto BV; Royal PTT Nederland NV, PTT Research;
Katholieke Universiteit Leuven; and Aarhus Universitet. After calls for
algorithms in 1989 and 1991 [<a href="Applied%20Cryptography_split_036.html#r1564" class="calibre5 pcalibre">1564</a>], 32 submissions from around the world,
and a 350 man-month evaluation project, the consortium published <i class="calibre12">RIPE</i>
<i class="calibre12">Integrity Primitives</i> [<a href="Applied%20Cryptography_split_036.html#r1305" class="calibre5 pcalibre">1305</a>,<a href="Applied%20Cryptography_split_036.html#r1332" class="calibre5 pcalibre">1332</a>]. The report included an introduction and
some basic integrity concepts, and these primitives: MDC-4 (see <a href="Applied%20Cryptography_split_021.html#18.11" class="calibre5 pcalibre">Section 18.11</a>),
RIPE-MD (see <a href="Applied%20Cryptography_split_021.html#18.8" class="calibre5 pcalibre">Section 18.8</a>), RIPE-MAC (see <a href="Applied%20Cryptography_split_021.html#18.14" class="calibre5 pcalibre">Section 18.14</a>),
IBC-HASH, SKID (see <a href="Applied%20Cryptography_split_004.html#3.2" class="calibre5 pcalibre">Section 3.2</a>), RSA, COMSET (see <a href="Applied%20Cryptography_split_019.html#16.1" class="calibre5 pcalibre">Section 16.1</a>), and
RSA key generation.</p>

<h3 id="25.8" class="calibre7">25.8 Conditional Access for Europe (CAFE)</h3>

<p class="calibre9">Conditional Access for Europe (CAFE) is a project in the European
Community’s ESPRIT program [<a href="Applied%20Cryptography_split_035.html#r204" class="calibre5 pcalibre">204</a>,<a href="Applied%20Cryptography_split_035.html#r205" class="calibre5 pcalibre">205</a>]. Work began in December 1992 and
is scheduled to be finished by the end of 1995. The consortium involved
consists of groups for social and market studies (Cardware, Institut für
Sozialforschung), software and hardware manufacturers (DigiCash, Gemplus,
Ingenico, Siemens), and cryptographers (CWI Amsterdam, PTT Research
Netherlands, SPET, Sintef Delab Trondheim, Universities of Århus,
Hildesheim and Leuven).</p>

<p class="calibre9">The goal is to develop systems for conditional access, particularly digital
payment systems. Payment systems must give legal certainty to everybody at
all times and require as little trust as possible — this certainty should not
depend on the tamper-resistance of any devices.</p>

<p class="calibre9">The basic device for CAFE is an electronic wallet: a small computer that looks
something like a pocket calculator. It has a battery, keyboard, screen, and an
infrared channel for communicating with other wallets. Every user owns and
uses his own wallet, which administers his rights and guarantees his security.</p>

<p class="calibre9">A device with a keyboard and screen has an advantage over a smart card; it
can operate independent of a terminal. A user can directly enter his password
and the amount of the payment. The user does not have to give his wallet up to
complete a transaction, unlike the current situation with credit cards.</p>

<p class="calibre9">Additional features are:</p>

<ul class="calibre13">

<li class="calibre14"> Offline transactions. The purpose of the system is to replace small
cash transactions; an online system would be too cumbersome.
</li>
<li class="calibre14"> Loss tolerance. If a user loses his wallet, or if it breaks or is stolen,
he can recover his money.
</li>
<li class="calibre14"> Support for different currencies.
</li>
<li class="calibre14"> An open architecture and open system. A user should be able to pay
for arbitrary services, such as shopping, telephone, and public transport,
by a range of service providers. The system should be interoperable
between any number of electronic money issuers, and between different
wallet types and manufacturers.
</li>
<li class="calibre14"> Low cost.
</li>

</ul>

<p class="calibre9">At this writing there is a software version of the system, and the consortium is
hard at work on a hardware prototype.</p>

<h3 id="25.9" class="calibre7">25.9 ISO/IEC 9979</h3>

<p class="calibre9">In the mid-80s, the ISO tried to standardize DES, which by then was already a
FIPS and an ANSI standard. After some political wrangling, the ISO decided
not to standardize cryptographic algorithms, but instead to register algorithms.
Only encryption algorithms can be registered; hash functions and signature
schemes cannot. Any national body can submit an algorithm for registration.</p>

<p class="calibre9">Currently only three algorithms have been submitted (see Table 25.4). A
submission includes information about applications, parameters,
implementations, modes, and test vectors. A detailed description is optional; it
is possible to submit secret algorithms for registration.</p>

<table class="data-table1" id="table-25-4">
<caption class="calibre67">Table 25.4 - ISO/IEC 9979 Registered Algorithms</caption>
<tbody class="calibre24"><tr class="calibre68">
<th class="calibre26">Name</th>
<th class="calibre26">Registration Number</th>
</tr>
<tr class="calibre25"><td class="calibre61">B-CRYPT</td><td class="calibre61">0001</td></tr>
<tr class="calibre71"><td class="calibre78">IDEA</td><td class="calibre78">0002</td></tr>
<tr class="calibre25"><td class="calibre61">LUC</td><td class="calibre61">0003</td></tr>
</tbody></table>

<p class="calibre39">The fact that an algorithm is registered does not imply anything about its
quality, nor is registration an approval of the algorithm by the ISO/IEC.
Registration merely indicates that a single national body wants to register the
algorithm, based on whatever criteria that body uses.</p>

<p class="calibre9">I am not impressed with this idea. Registration obstructs the standardization
process. Rather than agreeing on a few algorithms, the ISO is allowing any
algorithm to be registered. With so little control over what is registered, stating
that an algorithm is “ISO/IEC 9979 Registered” sounds a whole lot better than
it is. In any case, the registry is maintained by the <code class="calibre18">National Computer Centre
Ltd., Oxford Road, Manchester, M1 7ED, United Kingdom</code>.</p>

<h3 id="25.10" class="calibre7">25.10 Professional, Civil Liberties, and Industry Groups</h3>

<h4 class="calibre8">Electronic Privacy Information Center (EPIC)</h4>

<p class="calibre9">EPIC was established in 1994 to focus public attention on emerging privacy
issues relating to the National Information Infrastructure, such as the Clipper
chip, the Digital Telephony proposal, national identity numbers and systems,
medical records privacy, and the sale of consumer data. EPIC conducts
litigation, sponsors conferences, produces reports, publishes the <i class="calibre12">EPIC Alert</i>,
and leads campaigns on privacy issues. Anyone interested in joining should
contact <code class="calibre18">Electronic Privacy Information Center, 666 Pennsylvania Avenue SE,
Suite 301, Washington, D.C. 20003; (202) 544-9240; fax: (202) 547-5482;
Internet: info@epic.org</code>.</p>

<h4 class="calibre8">Electronic Frontier Foundation (EFF)</h4>

<p class="calibre9">The EFF is dedicated to protecting civil rights in cyberspace. With respect to
cryptographic policy in the United States, they believe that information and
access to cryptography are fundamental rights, and therefore should be free of
government restriction. They organized the Digital Privacy and Security
Working Group, a coalition of 50 organizations. The group opposed the
Digital Telephony bill and the Clipper initiative. The EFF is also helping in a
lawsuit against cryptography export controls [<a href="Applied%20Cryptography_split_035.html#r143" class="calibre5 pcalibre">143</a>]. Anyone interested in
joining the EFF should contact <code class="calibre18">Electronic Frontier Foundation, 1001 G Street
NW, Suite 950E, Washington, D.C. 20001; (202) 347-5400; fax: (202)
393-5509; Internet: eff@eff.org</code>.</p>

<h4 class="calibre8">Association for Computing Machinery (ACM)</h4>

<p class="calibre9">The ACM is an international computer industry organization. In 1994 the U.S.
ACM Public Policy Committee produced an excellent report on U.S.
cryptography policy [<a href="Applied%20Cryptography_split_036.html#r935" class="calibre5 pcalibre">935</a>]. This should be required reading for anyone
interested in the politics of cryptography. It is available via anonymous ftp
from info.acm.org in /reports/acm_crypto/acm_crypto_study.ps.</p>

<h4 class="calibre8">Institute of Electrical and Electronics Engineers (IEEE)</h4>

<p class="calibre9">The IEEE is another professional organization. The U.S. office investigates
and makes recommendations on privacy-related issues including encryption
policy, identity numbers, and privacy protections on the Internet.</p>

<h4 class="calibre8">Software Publishers Association (SPA)</h4>

<p class="calibre9">The SPA is a trade association of over 1000 personal computer software
companies. They have lobbied for relaxation of export controls on
cryptography, and maintain a list of commercially available foreign
cryptography products.</p>

<h3 id="25.11" class="calibre7">25.11 Sci.crypt</h3>

<p class="calibre9">Sci.crypt is the Usenet newsgroup for cryptology. It is read by an estimated
100,000 people worldwide. Most of the posts are nonsense, bickering, or both;
some are political, and most of the rest are requests for information or basic
questions. Occasionally nuggets of new and useful information are posted to
this newsgroup. If you follow sci.crypt regularly, you will learn how to use
something called a kill file.</p>

<p class="calibre9">Another Usenet newsgroup is sci.crypt.research, a moderated newsgroup
devoted to discussions about cryptology research. There are fewer posts and
they are more interesting.</p>

<h3 id="25.12" class="calibre7">25.12 Cypherpunks</h3>

<p class="calibre9">The Cypherpunks are an informal group of people interested in teaching and
learning about cryptography. They also experiment with cryptography and try
to put it into use. In their opinion, all the cryptographic research in the world
doesn’t do society any good unless it gets used.</p>

<p class="calibre9">In “A Cypherpunk’s Manifesto,” Eric Hughes writes [<a href="Applied%20Cryptography_split_035.html#r744" class="calibre5 pcalibre">744</a>]:</p>

<p class="quote">We the Cypherpunks are dedicated to building anonymous
systems. We are defending our privacy with cryptography, with
anonymous mail forwarding systems, with digital signatures, and
with electronic money.
<br class="calibre3"/><br class="calibre3"/>
Cypherpunks write code. We know that someone has to write
software to defend privacy, and since we can’t get privacy unless
we all do, we’re going to write it. We publish our code so that our
fellow Cypherpunks may practice and play with it. Our code is
free for all to use, worldwide. We don’t care much if you don’t
approve of the software we write. We know that software can’t be
destroyed and that widely dispersed systems can’t be shut down.</p>

<p class="calibre9">People interested in joining the cypherpunks mailing list on the Internet should
send mail to majordomo@toad.com. The mailing list is archived at
ftp.csua.berkeley.edu in /pub/cypherpunks.</p>

<h3 id="25.13" class="calibre7">25.13 Patents</h3>

<p class="calibre9">Software patents are an issue much larger than the scope of this book. Whether
they’re good or bad, they exist. Algorithms, cryptographic algorithms
included, can be patented in the United States. IBM owned the DES patents
[<a href="Applied%20Cryptography_split_035.html#r514" class="calibre5 pcalibre">514</a>]. IDEA is patented. Almost every public-key algorithm is patented. NIST
even has a patent for the DSA. Some cryptography patents have been blocked
by intervention from the NSA, under the authority of the Invention Secrecy
Act of 1940 and the National Security Act of 1947. This means that instead of
a patent, the inventor gets a secrecy order and is prohibited from discussing his
invention with anybody.</p>

<p class="calibre9">The NSA has special dispensation when it comes to patents. They can apply
for a patent and then block its issuance. It’s a secrecy order again, but here the
NSA is both the inventor and the issuer of the order. When, at some later date,
the secrecy order is removed, the Patent Office issues the patent good for the
standard 17 years. This rather clearly protects the invention while keeping it
secret. If someone else invents the same thing, the NSA has already filed for
the patent. If no one else invents it, then it remains secret.</p>

<p class="calibre9">Not only does this fly directly in the face of the patent process, which is
supposed to disclose as well as protect inventions, it allows the NSA to keep a
patent for more than 17 years. The 17-year clock starts ticking after the patent
is issued, not when it is filed. How this will change, now that the United States
has ratified the GATT treaty, is unclear.</p>

<h3 id="25.14" class="calibre7">25.14 U.S. Export Rules</h3>

<p class="calibre9">According to the U.S. government, cryptography can be a munition. This
means it is covered under the same rules as a TOW missile or an M1 Abrams
tank. If you sell cryptography overseas without the proper export license, then
you are an international arms smuggler. Unless you think time in a federal
penitentiary would look good on your résumé, pay attention to the rules.</p>

<p class="calibre9">With the advent of the Cold War in 1949, all of the NATO countries (except
Iceland), and later Australia, Japan, and Spain, formed CoCom, the
Coordinating Committee for Multilateral Export Controls. This is an unofficial
nontreaty organization, chartered to coordinate national restrictions on the
export of sensitive military technologies to the Soviet Union, other Warsaw
Pact countries, and the People’s Republic of China. Examples of controlled
technologies are computers, milling machinery, and cryptography. The goal
here was to slow technology transfer into those countries, and thereby keep
their militaries inferior.</p>

<p class="calibre9">Since the end of the Cold War, the CoCom countries realized that many of
their controls were obsolete. They are supposedly in the process of defining
something called the “New Forum,” another multinational organization
designed to stop the flow of military technologies to countries the members
don’t particularly like.</p>

<p class="calibre9">In any case, U.S. export policy on strategic goods is defined by the Export
Administration Act, the Arms Export Control Act, the Atomic Energy Act, and
the Nuclear Non-Proliferation Act. The controls established by all this
legislation are implemented through a number of statutes, none of them
coordinated with each other. Over a dozen agencies including the military
services administer controls; often their regulatory programs overlap and
contradict.</p>

<p class="calibre9">Controlled technologies appear on several lists. Cryptography has traditionally
been classified as a munition and appears on the U.S. Munitions List (USML),
the International Munitions List (IML), the Commerce Control List (CCL),
and the International Industrial List (IIL). The Department of State is
responsible for the USML; it is published as part of the International Traffic in
Arms Regulations (ITAR) [<a href="Applied%20Cryptography_split_035.html#r466" class="calibre5 pcalibre">466</a>,<a href="Applied%20Cryptography_split_035.html#r467" class="calibre5 pcalibre">467</a>].</p>

<p class="calibre9">Two U.S. government agencies control export of cryptography. One is the
Bureau of Export Administration (BXA) in the Department of Commerce,
authorized by the Export Administration Regulations (EAR). The other is the
Office of Defense Trade Controls (DTC) in the State Department, authorized
by the ITAR. As a rule of thumb, the Commerce Department’s BXA has far
less stringent requirements, but State Department’s DTC (which takes
technical and national security advice from the NSA, and always seems to
follow that advice) sees all cryptography exports first and can refuse to transfer
jurisdiction to BXA.</p>

<p class="calibre9">The ITAR regulates this stuff. (Before 1990 the Office of Defense Trade
Controls was called the Office of Munitions Controls; presumably this public
relations effort is designed to help us forget that we’re dealing with guns and
bombs.) Historically, the DTC has been reluctant to grant export licenses for
encryption products stronger than a certain level — not that they have ever been
public about exactly what that level is.</p>

<p class="calibre9">The following sections are excerpted from the ITAR [<a href="Applied%20Cryptography_split_035.html#r466" class="calibre5 pcalibre">466</a>,<a href="Applied%20Cryptography_split_035.html#r467" class="calibre5 pcalibre">467</a>]:</p>

<p class="quote">
§ 120.10 Technical data.
<br class="calibre3"/><br class="calibre3"/>
Technical data means, for purposes of this subchapter:
</p><ol class="calibre17">

<li class="calibre14">Information, other than software as defined in
120.10(d), which is required for the design, development,
production, processing, manufacture, assembly, operation,
repair, maintenance or modification of defense articles.
This includes, for example, information in the form of
blueprints, drawings, photographs, plans, instructions and
documentation;
</li>
<li class="calibre14">Classified information relating to defense articles and
defense services;
</li>
<li class="calibre14">Information covered by an invention secrecy order;
</li>
<li class="calibre14">Software as defined in Sec. 121.8(f) directly related to
defense articles;
</li>
<li class="calibre14">This definition does not include information
concerning general scientific, mathematical or engineering
principles commonly taught in schools, colleges and
universities in the public domain as defined in § 120.11. It
also does not include basic marketing information on
function or purpose or general system descriptions of
defense articles.
</li>

</ol>

§ 120.11 Public domain.
<br class="calibre3"/><br class="calibre3"/>
Public domain means information which is published and which
is generally accessible or available to the public:

<ol class="calibre17">

<li class="calibre14">Through sales at newsstands and bookstores;
</li>
<li class="calibre14">Through subscriptions which are available without
restriction to any individual who desires to obtain or
purchase the published information;
</li>
<li class="calibre14">Through second class mailing privileges granted by the
U.S. Government;
</li>
<li class="calibre14">At libraries open to the public or from which the public
can obtain documents;
</li>
<li class="calibre14">Through patents available at any patent office;
</li>
<li class="calibre14">Through unlimited distribution at a conference,
meeting, seminar, trade show or exhibition, generally
accessible to the public, in the United States;
</li>
<li class="calibre14">Through public release (i.e., unlimited distribution) in
any form (e.g., not necessarily in published form) after
approval by the cognizant U.S. government department or
agency (see also § 125.4(b)(13)).
</li>
<li class="calibre14">Through fundamental research in science and
engineering at accredited institutions of higher learning in
the U.S., where the resulting information is ordinarily
published and shared broadly in the scientific community.
Fundamental research is defined to mean basic and applied
research in science and engineering where the resulting
information is ordinarily published and shared broadly
within the scientific community, as distinguished from
research the results of which are restricted for proprietary
reasons or specific U.S. Government access and
dissemination controls. University research will not be
considered fundamental research if:

<ol class="calibre97">
<li class="calibre14">The University or its researchers accept other
restrictions on publication of scientific and technical
information resulting from the project or activity, or</li>
<li class="calibre14">The research is funded by the U.S. Government and
specific access and dissemination controls protecting
information resulting from the research are applicable.</li>
</ol>
</li>

</ol>

§ 120.17 Export.
<br class="calibre3"/><br class="calibre3"/>
Export means:

<ol class="calibre17">

<li class="calibre14">Sending or taking defense articles out of the United
States in any manner, except by mere travel outside of the
United States by a person whose personal knowledge
includes technical data; or
</li>
<li class="calibre14">Transferring registration, control or ownership to a
foreign person of any aircraft, vessel, or satellite covered
by the U.S. Munitions List, whether in the United States or
abroad; or
</li>
<li class="calibre14">Disclosing (including oral or visual disclosure) or
transferring in the United States any defense articles to an
embassy, any agency or subdivision of a foreign
government (e.g., diplomatic missions); or
</li>
<li class="calibre14">Disclosing (including oral or visual disclosure) or
transferring technical data to a foreign person, whether in
the United States or abroad; or
</li>
<li class="calibre14">Performing a defense service on behalf of, or for the
benefit of, a foreign person, whether in the United States or
abroad.
</li>
<li class="calibre14">A launch vehicle or payload shall not, by the launching
of such vehicle, be considered export for the purposes of
this subchapter. However, for certain limited purposes (see
§ 126.1 of this subchapter), the controls of this subchapter
apply to sales and other transfers of defense articles or
defense services.
</li>

</ol>

Part 121 — The United States Munitions List
<br class="calibre3"/><br class="calibre3"/>
§ 121.1 General. The United States Munitions List
<br class="calibre3"/><br class="calibre3"/>
Category XIII — Auxiliary Military Equipment

<ol class="calibre17">

<li class="calibre14">Cryptographic (including key management) systems,
equipment, assemblies, modules, integrated circuits,
components or software with the capability of maintaining
secrecy or confidentiality of information or information
systems, except cryptographic equipment and software as
follows:

<ol class="calibre97">
<li class="calibre14">Restricted to decryption functions specifically designed
to allow the execution of copy protected software, provided
the decryption functions are not user-accessible.</li>
<li class="calibre14">Specifically designed, developed or modified for use in
machines for banking or money transactions, and restricted
to use only in such transactions. Machines for banking or
money transactions include automatic teller machines,
self-service statement printers, point of sale terminals or
equipment for the encryption of interbanking transactions.</li>
<li class="calibre14">Employing only analog techniques to provide the
cryptographic processing that ensures information security
in the following applications....</li>
<li class="calibre14">Personalized smart cards using cryptography restricted
for use only in equipment or systems exempted from the
controls of the USML.</li>
<li class="calibre14">Limited to access control, such as automatic teller
machines, self-service statement printers or point of sale
terminals, which protects passwords or personal
identification numbers (PIN) or similar data to prevent
unauthorized access to facilities but does not allow for
encryption or files or text, except as directly related to the
password of PIN protection.</li>
<li class="calibre14">Limited to data authentication which calculates a
Message Authentication Code (MAC) or similar result to
ensure no alteration of text has taken place, or authenticate
users, but does not allow for encryption of data, text or
other media other than that needed for the authentication.</li>
<li class="calibre14">Restricted for fixed data compression or coding
techniques.</li>
<li class="calibre14">Limited to receiving for radio broadcast, pay
television or similar restricted audience television of the
consumer type, without digital encryption and where digital
decryption is limited to video, audio or management
functions.</li>
<li class="calibre14">Software designed or modified to protect against
malicious computer damage, (e.g., viruses).</li>
</ol>

</li>

<li class="calibre14">Cryptographic (including key management) systems,
equipment, assemblies, modules, integrated circuits,
components or software which have the capability of
generating spreading or hopping codes for spread spectrum
systems or equipment.
</li>
<li class="calibre14">Cryptographic systems, equipment, assemblies,
modules, integrated circuits, components or software.
</li>

</ol>

§ 125.2 Exports of unclassified technical data.

<ol class="calibre98">

<li class="calibre14">General. A license (DSP-5) is required for the export of
unclassified technical data unless the export is exempt from
the licensing requirements of this subchapter. In the case of
a plant visit, details of the proposed discussions must be
transmitted to the Office of Defense Trade Controls for an
appraisal of the technical data. Seven copies of the
technical data or the details of the discussions must be
provided.</li>
<li class="calibre14">Patents. A license issued by the Office of Defense
Trade Controls is required for the export of technical data
whenever the data exceeds that which is used to support a
domestic filing of a patent application or to support a
foreign filing of a patent application whenever no domestic
application has been filed. Requests for the filing of patent
applications in a foreign country, and requests for the filing
of amendments, modifications or supplements to such
patents, should follow the regulations of the U.S. Patent
and Trademark Office in accordance with 37 CFR part 5.
The export of technical data to support the filing and
processing of patent applications in foreign countries is
subject to regulations issued by the U.S. Patent and
Trademark Office pursuant to 35 U.S.C. 184.</li>
<li class="calibre14">Disclosures. Unless otherwise expressly exempted in
this subchapter, a license is required for the oral, visual or
documentary disclosure of technical data by U.S. persons to
foreign persons. A license is required regardless of the
manner in which the technical data is transmitted (e.g., in
person, by telephone, correspondence, electronic means,
etc.). A license is required for such disclosures by U.S.
persons in connection with visits to foreign diplomatic
missions and consular offices.
</li>

</ol>

<p class="calibre9"></p>

<p class="calibre9">And so on. There’s a lot more information in this document. If you’re going to
try to export cryptography, I suggest you get a copy of the entire thing and a
lawyer who speaks the language.</p>

<p class="calibre9">In reality, the NSA has control over the export of cryptographic products. If
you want a Commodity Jurisdiction (CJ), you must submit your product to the
NSA for approval and submit the CJ application to the State Department. After
State Department approval, the matter moves under the jurisdiction of the
Commerce Department, which has never cared much about the export of
cryptography. However, the State Department will never grant a CJ without
NSA approval.</p>

<p class="calibre9">In 1977 an NSA employee named Joseph A. Meyer wrote a
letter — unauthorized, according to the official story of the incident — to the
IEEE, warning them that the scheduled presentation of the original RSA paper
would violate the ITAR. From <i class="calibre12">The Puzzle Palace:</i></p>

<p class="quote">He had a point. The ITAR did cover any “unclassified
information that can be used, or adapted for use, in the design,
production, manufacture, repair, overhaul, processing,
engineering, development, operation, maintenance, or
reconstruction” of the listed materials, as well as “any technology
which advances the state-of-the-art or establishes a new art in an
area of significant military applicability in the United States.”
And export did include transferring the information both by
writing and by either oral or visual means, including briefings and
symposia in which foreign nationals are present.
<br class="calibre3"/><br class="calibre3"/>
But followed literally, the vague, overly broad regulations would
seem to require that anyone planning to write or speak out
publicly on a topic touching the Munitions List must first get
approval from the State Department — a chilling prospect clearly
at odds with the First Amendment and one as yet untested by the
Supreme Court.</p>

<p class="calibre9">In the end NSA disavowed Meyer’s actions and the RSA paper was presented
as planned. No actions were taken against any of the inventors, although their
work arguably enhanced foreign cryptography capabilities more than anything
released since.</p>

<p class="calibre9">The following statement by NSA discusses the export of cryptography [<a href="Applied%20Cryptography_split_035.html#r363" class="calibre5 pcalibre">363</a>]:</p>

<p class="quote">Cryptographic technology is deemed vital to national security
interests. This includes economic, military, and foreign policy
interests.
<br class="calibre3"/><br class="calibre3"/>
We do not agree with the implications from the House Judiciary
Committee hearing of 7 May 1992 and recent news articles that
allege that U.S. export laws prevent U.S. firms’ manufacture and
use of top encryption equipment. We are unaware of any case
where a U.S. firm has been prevented from manufacturing and
using encryption equipment within this country or for use by the
U.S. firm or its subsidiaries in locations outside the U.S. because
of U.S. export restrictions. In fact, NSA has always supported the
use of encryption by U.S. businesses operating domestically and
overseas to protect sensitive information.
<br class="calibre3"/><br class="calibre3"/>
For export to foreign countries, NSA as a component of the
Department of Defense (along with the Department of State and
the Department of Commerce) reviews export licenses for
information security technologies controlled by the Export
Administration Regulations or the International Traffic in Arms
Regulations. Similar export control systems are in effect in all the
Coordinating Committee for Multilateral Export Controls
(CoCom) countries as well as many non-CoCom countries as
these technologies are universally considered as sensitive. Such
technologies are not banned from export and are reviewed on a
case-by-case basis. As part of the export review process, licenses
may be required for these systems and are reviewed to determine
the effect such export could have on national security
interests — including economic, military, and political security
interests. Export licenses are approved or denied based upon the
type of equipment involved, the proposed end use and the end
user.
<br class="calibre3"/><br class="calibre3"/>
Our analysis indicates that the U.S. leads the world in the
manufacture and export of information security technologies. Of
those cryptologic products referred to NSA by the Department of
State for export licenses, we consistently approve over 90%.
Export licenses for information security products under the
jurisdiction of the Department of Commerce are processed and
approved without referral to NSA or DoD. This includes products
using such techniques as the DSS and RSA which provide
authentication and access control to computers or networks. In
fact, in the past NSA has played a major role in successfully
advocating the relaxation of export controls on RSA and related
technologies for authentication purposes. Such techniques are
extremely valuable against the hacker problem and unauthorized
use of resources.</p>

<p class="calibre9">It is the stated policy of the NSA not to restrict the export of authentication
products, only encryption products. If you want to export an
authentication-only product, approval may merely be a matter of showing that
your product cannot easily be used for encryption. Furthermore, the
bureaucratic procedures are much simpler for authentication products than for
encryption products. An authentication product needs State Department
approval only once for a CJ; an encryption product may require approval for
every product revision or even every sale.</p>

<p class="calibre9">Without a CJ, you must request export approval every time you wish to export
the product. The State Department does not approve the export of products
with strong encryption, even those using DES. Isolated exceptions include
export to U.S. subsidiaries for the purposes of communicating to the U.S.,
exports for some banking applications, and export to appropriate U.S. military
users. The Software Publishers Association (SPA) has been negotiating with
the government to ease export license restrictions. A 1992 agreement between
them and the State Department eased the export license rules for two
algorithms, RC2 and RC4, as long as the key size is 40 bits or less. Refer to
<a href="Applied%20Cryptography_split_009.html#7.1" class="calibre5 pcalibre">Section 7.1</a> for more information.</p>

<p class="calibre9">In 1993, Rep. Maria Cantwell (D-WA) introduced a bill at the behest of the
software industry to relax export controls on encryption software. Sen. Patty
Murray (D-WA) introduced a companion bill in the Senate. The Cantwell Bill
was appended to the general export control legislation going through
Congress, but was deleted by the House Intelligence Committee after a
massive lobbying effort by the NSA. Whatever the NSA did, it was
impressive; the committee voted unanimously to delete the wording. I can’t
remember the last time a bunch of legislators voted unanimously to do
anything.</p>

<p class="calibre9">In 1995 Dan Bernstein, with the help of the EFF, sued the U.S. government,
seeking to bar the government from restricting publication of cryptographic
documents and software [<a href="Applied%20Cryptography_split_035.html#r143" class="calibre5 pcalibre">143</a>]. The suit claimed that the export control laws
are unconstitutional, an “impermissible prior restraint on speech, in violation
of the First Amendment.” Specifically, the lawsuit charges that the current
export control process:</p>

<ul class="calibre13">

<li class="calibre14">Allows bureaucrats to restrict publication without ever going to
court.
</li>
<li class="calibre14">Provides too few procedural safeguards for First Amendment rights.
</li>
<li class="calibre14">Requires publishers to register with the government, creating in
effect a “licensed press.”
</li>
<li class="calibre14">Disallows general publication by requiring recipients to be
individually identified.
</li>
<li class="calibre14">Is sufficiently vague that ordinary people cannot know what conduct
is allowed and what conduct is prohibited.
</li>
<li class="calibre14">Is overbroad because it prohibits conduct that is clearly protected
(such as speaking to foreigners within the United States).
</li>
<li class="calibre14">Is applied too broadly, by prohibiting export of software that
contains no cryptography, on the theory that cryptography could be
added to it later.
</li>
<li class="calibre14">Egregiously violates the First Amendment by prohibiting private
speech on cryptography because the government wishes its own
opinions on cryptography to guide the public instead.
</li>
<li class="calibre14">Exceeds the authority granted by Congress in the export control laws
in many ways, as well as exceeding the authority granted by the
Constitution.
</li>

</ul>

<p class="calibre9">Everyone anticipates that the case will take several years to settle, and no one
has any idea how it will come out.</p>

<p class="calibre9">Meanwhile, the Computer Security and Privacy Advisory Board, an official
advisory board to NIST, voted in March 1992 to recommend a national policy
review of cryptographic issues, including export policy. They said that export
policy is decided solely by agencies concerned with national security, without
input from agencies concerned with encouraging commerce. Those agencies
concerned with national security are doing everything possible to make sure
this doesn’t change, but eventually it has to.</p>

<h3 id="25.15" class="calibre7">25.15 Foreign Import and Export of Cryptography</h3>

<p class="calibre9">Other countries have their own import and export rules [<a href="Applied%20Cryptography_split_035.html#r311" class="calibre5 pcalibre">311</a>]. This summary is
incomplete and probably out of date. Countries could have rules and ignore
them, or could have no rules but restrict import, export, and use anyway.</p>

<ul class="calibre13">

<li class="calibre14">Australia requires an import certificate for cryptography only upon
request from the exporting country.
</li>
<li class="calibre14">Canada has no import controls, and export controls are similar to
those of the United States. The exportation of items from Canada may
be subject to restriction if they are included on the Export Control List
pursuant to the Export and Import Permits Act. Canada follows the
CoCom regulations in the regulation of cryptographic technology.
Encryption devices are outlined in category five, part two of Canada’s
export regulations. These provisions are similar to U.S. category five in
the Export Administration Regulations.
</li>
<li class="calibre14">China has a licensing scheme for importing commodities; exporters
must file an application with the Ministry of Foreign Trade. Based on
China’s List of Prohibited and Restricted Imports and Exports enacted
in 1987, China restricts the import and export of voice-encoding
devices.
</li>
<li class="calibre14">France has no special rules for the import of cryptography, but they
have rules regarding the sale and use of cryptography in their country.
All products must be certified: Either they must meet a published
specification, or the company proprietary specification must be provided
to the government. The government may also ask for two units for their
own use. Companies must have a license to sell cryptography within
France; the license specifies the target market. Users must have a license
to buy and use cryptography; the license includes a statement to the
effect that users must be prepared to give up their keys to the
government up to four months after use. This restriction may be waived
in some cases: for banks, large companies, and so on. And there is no
use license requirement for cryptography exportable from the U.S.
</li>
<li class="calibre14">Germany follows the CoCom guidelines, requiring a license to
export cryptography. They specifically maintain control of
public-domain and mass-market cryptography software.
</li>
<li class="calibre14">Israel has import restrictions, but no one seems to know what they
are.
</li>
<li class="calibre14">Belgium, Italy, Japan, Netherlands, and the United Kingdom follow
the CoCom guidelines on cryptography, requiring a license for export.
</li>
<li class="calibre14">Brazil, India, Mexico, Russia, Saudi Arabia, Spain, South Africa,
Sweden, and Switzerland have no import or export controls on
cryptography.
</li>

</ul>

<h3 id="25.16" class="calibre7">25.16 Legal Issues</h3>

<p class="calibre9">Are digital signatures real signatures? Will they stand up in court? Some
preliminary legal research has resulted in the opinion that digital signatures
would meet the requirements of legally binding signatures for most purposes,
including commercial use as defined in the Uniform Commercial Code (UCC).
A GAO (General Accounting Office) decision, made at the request of NIST,
opines that digital signatures will meet the legal standards of handwritten
signatures [<a href="Applied%20Cryptography_split_035.html#r362" class="calibre5 pcalibre">362</a>].</p>

<p class="calibre9">The Utah Digital Signature Act went into effect on May 1, 1995, providing a
legal framework for the use of digital signatures in the judicial system.
California has a bill pending, while Oregon and Washington are still writing
theirs. Texas and Florida are right behind. By this book’s publication, more
states will have followed suit.</p>

<p class="calibre9">The American Bar Association (EDI and Information Technology Division of
the Science and Technology Section) produced a model act for states to use for
their own legislation. The act attempts to incorporate digital signatures into the
existing legal infrastructure for signatures: the Uniform Commercial Code, the
United States Federal Reserve regulations, common law of contracts and
signatures, the United Nations Convention on Contracts for the International
Sale of Goods, and the United Nations Convention on International Bills of
Exchange and International Promissory Committees. Included in the act are
responsibilities and obligations of certification authorities, issues of liability,
and limits and policies.</p>

<p class="calibre9">In the United States, laws about signatures, contracts, and commercial
transactions are state laws, so this model act is designed for states. The
eventual goal is a federal act, but if this all begins at the state level there is less chance of the NSA mucking up the works.</p>

<p class="calibre9">Even so, the validity of digital signatures has not been challenged in court;
their legal status is still undefined. In order for digital signatures to carry the
same authority as handwritten signatures, they must first be used to sign a
legally binding document, and then be challenged in court by one party. The
court would then consider the security of the signature scheme and issue a
ruling. Over time, as this happened repeatedly, a body of precedent rulings
would emerge regarding which digital signature methods and what key sizes
are required for a digital signature to be legally binding. This is likely to take
years.</p>

<p class="calibre9">Until then, if two people wish to use digital signatures for contracts (or
purchase requests, or work orders, or whatever), it is recommended that they
sign a paper contract in which they agree in the future to be bound by any
documents digitally signed by them [<a href="Applied%20Cryptography_split_036.html#r1099" class="calibre5 pcalibre">1099</a>]. This document would specify
algorithm, key size, and any other parameters; it should also delineate how
disputes would be resolved.</p>

</div>






</body></html>
